{"meta":{"title":"嘻嘻疯子的android小站","subtitle":null,"description":"android开发 学习 工作 生活","author":"gagapencil","url":"https://hesitationpencil.github.io","root":"/"},"pages":[],"posts":[{"title":"深入理解linux中内存管理","slug":"深入理解Linux中内存管理","date":"2019-06-23T07:19:14.000Z","updated":"2019-06-23T10:07:05.257Z","comments":true,"path":"2019/06/23/深入理解Linux中内存管理/","link":"","permalink":"https://hesitationpencil.github.io/2019/06/23/深入理解Linux中内存管理/","excerpt":"","text":"[TOC] 前言c程序运行在linux进程中，要想弄清楚c程序运行时内存需要搞清楚进程空间，而要搞清楚进程空间 虚拟内存是必须要了解的。毋庸置疑，虚拟内存绝对是操作系统中最重要的概念之一。我想主要是由于内存的重要”战略地位”。CPU太快，但容量小且功能单一，其他 I/O 硬件支持各种花式功能，可是相对于 CPU，它们又太慢。于是它们之间就需要一种润滑剂来作为缓冲，这就是内存大显身手的地方。而在现代操作系统中，多任务已是标配。多任务并行，大大提升了 CPU 利用率，但却引出了多个进程对内存操作的冲突问题，虚拟内存概念的提出就是为了解决这个问题。 由来：回顾一下历史，在早期的计算机中，程序是直接运行在物理内存上的。换句话说，就是程序在运行的过程中访问的都是物理地址。如果这个系统只运行一个程序，那么只要这个程序所需的内存不要超过该机器的物理内存就不会出现问题，我们也就不需要考虑内存管理这个麻烦事了，反正就你一个程序，就这么点内存，吃不吃得饱那是你的事情了。然而现在的系统都是支持多任务，多进程的，这样CPU以及其他硬件的利用率会更高，这个时候我们就要考虑到将系统内有限的物理内存如何及时有效的分配给多个程序了，这个事情本身我们就称之为内存管理。举一个早期的计算机系统中，内存分配管理的例子，以便于理解。 假如我们有三个程序，程序A，B，C，程序A运行的过程中需要10M内存，程序B运行的过程中需要100M内存，而程序C运行的过程中需要20M内存。如果系统同时需要运行程序A和B，那么早期的内存管理过程大概是这样的，将物理内存的前10M分配给A，接下来的10M-110M分配给B。这种内存管理的方法比较直接，好了，假设我们这个时候想让程序C也运行，同时假设我们系统的内存只有128M，显然按照这种方法程序C由于内存不够是不能够运行的。大家知道可以使用虚拟内存的技术，内存空间不够的时候可以将程序不需要用到的数据交换到磁盘空间上去，已达到扩展内存空间的目的。 这种内存管理方式存在的几个比较明显的问题。 进程地址空间不能隔离，由于程序直接访问的是物理内存，这个时候程序所使用的内存空间不是隔离的。就像上面说的A的地址空间是0-10M这个范围内，但是如果A中有一段代码是操作10M-128M这段地址空间内的数据，那么程序B和程序C就很可能会崩溃（每个程序都可以访问系统的整个地址空间）。这样很多恶意程序或者是木马程序可以轻而易举地破快其他的程序，系统的安全性也就得不到保障了，这对用户来说也是不能容忍的。 内存使用的效率低，如上面提到的，如果我们要像让程序A、B、C同时运行，那么唯一的方法就是使用虚拟内存技术将一些程序暂时不用的数据写到磁盘上，在需要的时候再从磁盘读回内存。这里程序C要运行，将A交换到磁盘上去显然是不行的，因为程序是需要连续的地址空间的，程序C需要20M的内存，而A只有10M的空间，所以需要将程序B交换到磁盘上去，而B足足有100M，可以看到为了运行程序C我们需要将100M的数据从内存写到磁盘，然后在程序B需要运行的时候再从磁盘读到内存，我们知道IO操作比较耗时，所以这个过程效率将会十分低下。 程序运行的地址不能确定。程序每次需要运行时，都需要在内存中分配一块足够大的空闲区域，而问题是这个空闲的位置是不能确定的，这会带来一些重定位的问题，重定位的问题确定就是程序中引用的变量和函数的地址。 内存管理无非就是想办法解决上面三个问题，如何使进程的地址空间隔离，如何提高内存的使用效率，如何解决程序运行时的重定位问题？引用计算机界一句无从考证的名言：“计算机系统里的任何问题都可以靠引入一个中间层来解决。”现在的内存管理方法就是在程序和物理内存之间引入了虚拟内存这个概念。 虚拟内存位于程序和物理内存之间，程序只能看见虚拟内存，再也不能直接访问物理内存。 每个程序都有自己独立的进程地址空间，这样就做到了进程隔离。这里的进程地址空间是指虚拟地址。 顾名思义，既然是虚拟地址，也就是虚的，不是现实存在的地址空间。 虚拟内存机制虚拟内存的实现主要通过分页机制，早期是通过分段 分段这种方法是人们最开始使用的一种方法，基本思路是将程序所需要的内存地址空间大小的虚拟空间映射到某个物理地址空间。 这种分段的机制解决了开始提到的3个问题中的进程地址空间隔离和程序地址重定位的问题,但是对于内存效率问题仍然无能为力。 程序A和程序B有自己独立的虚拟地址空间，而且该虚拟地址空间被映射到了互相不重叠的物理地址空间，如果程序A访问虚拟地址空间的地址不在0x00000000-0x00A00000这个范围内，那么内核就会拒绝这个请求，所以它解决了隔离地址空间的问题。我们应用程序A只需要关心其虚拟地址空间0x00000000-0x00A00000，而其被映射到哪个物理地址我们无需关心，所以程序永远按照这个虚拟地址空间来放置变量，代码，不需要重新定位。 这种内存映射机制仍然是以程序为单位，当内存不足时仍然需要将整个程序交换到磁盘，这样内存使用的效率仍然很低。那么，怎么才算高效率的内存使用呢。事实上，根据程序的局部性运行原理，一个程序在运行的过程当中，在某个时间段内，只有一小部分数据会被经常用到。所以我们需要更加小粒度的内存分割和映射方法，此时是否会想到Linux中的Buddy算法和slab内存分配机制呢。另一种将虚拟地址转换为物理地址的方法分页机制应运而生了。 分页机制分页机制就是把内存地址空间分为若干个很小的固定大小的页，每一页的大小由内存决定，就像Linux中ext文件系统将磁盘分成若干个Block一样，这样做是分别是为了提高内存和磁盘的利用率。 试想一下，如果将磁盘空间分成N等份，每一份的大小(一个Block)是1M，如果我想存储在磁盘上的文件是1K字节，那么其余的999字节是不是浪费了。所以需要更加细粒度的磁盘分割方式，我们可以将Block设置得小一点，这当然是根据所存放文件的大小来综合考虑的，好像有点跑题了，我只是想说，内存中的分页机制跟ext文件系统中的磁盘分割机制非常相似。 如果分的太小了也不行。我们知道系统里的基本单位都是 Byte 字节，如果将每一个虚拟内存的 Byte 都对应到物理内存的地址，每个条目最少需要 8字节（32位虚拟地址-&gt;32位物理地址），在 4G 内存的情况下，就需要 32GB 的空间来存放对照表，那么这张表就大得真正的物理地址也放不下了，于是操作系统引入了 页（Page）的概念。 Linux中一般页的大小是4KB，我们把进程的地址空间按页分割，把常用的数据和代码页装载到内存中，不常用的代码和数据保存在磁盘中，我们还是以一个例子来说明,如下图： 可以看到进程1和进程2的虚拟地址空间都被映射到了不连续的物理地址空间内(这个意义很大，如果有一天我们的连续物理地址空间不够，但是不连续的地址空间很多，如果没有这种技术，我们的程序就没有办法运行)，甚至他们共用了一部分物理地址空间，这就是共享内存。 进程1的虚拟页VP2和VP3被交换到了磁盘中，在程序需要这两页的时候，Linux内核会产生一个缺页异常，然后异常管理程序会将其读到内存中。 这就是分页机制的原理，当然Linux中的分页机制的实现还是比较复杂的，通过了页全局目录，页上级目录，页中级目录，页表等几级的分页机制来实现的，但是基本的工作原理是不会变的。 分页机制的实现需要硬件的实现，这个硬件名字叫做MMU(Memory Management Unit)，他就是专门负责从虚拟地址到物理地址转换的，也就是从虚拟页找到物理页。 ###SWAP我们前文提到了虚拟内存通过缺页中断为进程分配物理内存，内存总是有限的，如果所有的物理内存都被占用了怎么办呢？ Linux 提出 SWAP 的概念，Linux 中可以使用 SWAP 分区，在分配物理内存，但可用内存不足时，将暂时不用的内存数据先放到磁盘上，让有需要的进程先使用，等进程再需要使用这些数据时，再将这些数据加载到内存中，通过这种”交换”技术，Linux 可以让进程使用更多的内存。 进程虚拟地址空间分布在多任务操作系统中，每个进程都运行在属于自己的内存沙盘中。这个沙盘就是虚拟地址空间(Virtual Address Space)，在32位模式下它是一个4GB的内存地址块。在Linux系统中, 内核进程和用户进程所占的虚拟内存比例是1:3，而Windows系统为2:2(通过设置Large-Address-Aware Executables标志也可为1:3)。这并不意味着内核使用那么多物理内存，仅表示它可支配这部分地址空间，根据需要将其映射到物理内存。 虚拟地址通过页表(Page Table)映射到物理内存，页表由操作系统维护并被处理器引用。内核空间在页表中拥有较高特权级，因此用户态程序试图访问这些页时会导致一个页错误(page fault)。在Linux中，内核空间是持续存在的，并且在所有进程中都映射到同样的物理内存。内核代码和数据总是可寻址，随时准备处理中断和系统调用。与此相反，用户模式地址空间的映射随进程切换的发生而不断变化。Linux进程在虚拟内存中的标准内存段布局如下图所示： 其中，用户地址空间中的蓝色条带对应于映射到物理内存的不同内存段，灰白区域表示未映射的部分。这些段只是简单的内存地址范围，与Intel处理器的段没有关系。 用户进程部分分段存储内容如下表所示(按地址递减顺序)： 名称 存储内容 栈 局部变量、函数参数、返回地址等 堆 动态分配的内存 BSS段 未初始化或初值为0的全局变量和静态局部变量 数据段 已初始化且初值非0的全局变量和静态局部变量 代码段 可执行代码、字符串字面值、只读变量 在将应用程序加载到内存空间执行时，操作系统负责代码段、数据段和BSS段的加载，并在内存中为这些段分配空间。栈也由操作系统分配和管理；堆由程序员自己管理，即显式地申请和释放空间。BSS段、数据段和代码段是可执行程序编译时的分段，运行时还需要栈和堆。 以下详细介绍各个分段的含义。 内核空间内核总是驻留在内存中，是操作系统的一部分。内核空间为内核保留，不允许应用程序读写该区域的内容或直接调用内核代码定义的函数。 栈(stack)栈又称堆栈，由编译器自动分配释放，行为类似数据结构中的栈(先进后出)。堆栈主要有三个用途： 为函数内部声明的非静态局部变量(C语言中称“自动变量”)提供存储空间。 记录函数调用过程相关的维护性信息，称为栈帧(Stack Frame)或过程活动记录(Procedure Activation Record)。它包括函数返回地址，不适合装入寄存器的函数参数及一些寄存器值的保存。除递归调用外，堆栈并非必需。因为编译时可获知局部变量，参数和返回地址所需空间，并将其分配于BSS段。 临时存储区，用于暂存长算术表达式部分计算结果或alloca()函数分配的栈内内存。 持续地重用栈空间有助于使活跃的栈内存保持在CPU缓存中，从而加速访问。进程中的每个线程都有属于自己的栈。向栈中不断压入数据时，若超出其容量就会耗尽栈对应的内存区域，从而触发一个页错误。此时若栈的大小低于堆栈最大值RLIMIT_STACK(通常是8M)，则栈会动态增长，程序继续运行。映射的栈区扩展到所需大小后，不再收缩。 Linux中ulimit -s命令可查看和设置堆栈最大值，当程序使用的堆栈超过该值时, 发生栈溢出(Stack Overflow)，程序收到一个段错误(Segmentation Fault)。注意，调高堆栈容量可能会增加内存开销和启动时间。 堆栈既可向下增长(向内存低地址)也可向上增长, 这依赖于具体的实现。本文所述堆栈向下增长。 堆栈的大小在运行时由内核动态调整。 BSS段BSS(Block Started by Symbol)段中通常存放程序中以下符号： 未初始化的全局变量和静态局部变量 初始值为0的全局变量和静态局部变量(依赖于编译器实现) 未定义且初值不为0的符号(该初值即common block的大小) 数据段(Data)数据段通常用于存放程序中已初始化且初值不为0的全局变量和静态局部变量。数据段属于静态内存分配(静态存储区)，可读可写。 数据段保存在目标文件中(在嵌入式系统里一般固化在镜像文件中)，其内容由程序初始化。例如，对于全局变量int gVar = 10，必须在目标文件数据段中保存10这个数据，然后在程序加载时复制到相应的内存。 数据段与BSS段的区别如下： BSS段不占用物理文件尺寸，但占用内存空间；数据段占用物理文件，也占用内存空间。对于大型数组如int ar0[10000] = {1, 2, 3, …}和int ar1[10000]，ar1放在BSS段，只记录共有10000*4个字节需要初始化为0，而不是像ar0那样记录每个数据1、2、3…，此时BSS为目标文件所节省的磁盘空间相当可观。 当程序读取数据段的数据时，系统会出发缺页故障，从而分配相应的物理内存；当程序读取BSS段的数据时，内核会将其转到一个全零页面，不会发生缺页故障，也不会为其分配相应的物理内存。 运行时数据段和BSS段的整个区段通常称为数据区。某些资料中“数据段”指代数据段 + BSS段 + 堆。 代码段(text)代码段也称正文段或文本段，通常用于存放程序执行代码(即CPU执行的机器指令)。一般C语言执行语句都编译成机器代码保存在代码段。通常代码段是可共享的，因此频繁执行的程序只需要在内存中拥有一份拷贝即可。代码段通常属于只读，以防止其他程序意外地修改其指令(对该段的写操作将导致段错误)。某些架构也允许代码段为可写，即允许修改程序。 代码段指令根据程序设计流程依次执行，对于顺序指令，只会执行一次(每个进程)；若有反复，则需使用跳转指令；若进行递归，则需要借助栈来实现。 代码段指令中包括操作码和操作对象(或对象地址引用)。若操作对象是立即数(具体数值)，将直接包含在代码中；若是局部数据，将在栈区分配空间，然后引用该数据地址；若位于BSS段和数据段，同样引用该数据地址。 代码段最容易受优化措施影响。 系统调用与内存管理（sbrk、brk、mmap、munmap）系统调用在Linux中，4G内存可分为两部分——内核空间1G（34G）与用户空间3G（03G）,我们通常写的C代码都是在对用户空间即0~3G的内存进行操作。而且，用户空间的代码不能直接访问内核空间，因此内核空间提供了一系列的函数，实现用户空间进入内核空间的接口，这一系列的函数称为系统调用（System Call）。比如我们经常使用的open、close、read、write等函数都是系统级别的函数（man 2 function_name），而像fopen、fclose、fread、fwrite等都是用户级别的函数（man 3 function_name）。不同级别的函数能够操作的内存区域自然也就不同。 我们用一幅图来描述函数的调用过程： 对于C++中new与delete的底层则是用malloc和free实现。而我们所用的malloc()、free()与内核之间的接口（桥梁）就是sbrk()等系统函数；当然我们也可以直接调用系统调用（系统函数）,达到同样的作用。我们可以用下面这幅图来描述基本内存相关操作之间的关系： 虽然使用系统调用会带来一定的好处，但是物极必反，系统调用并非能频繁使用。由于程序由用户进入内核层时，会将用户层的状态先封存起来，然后到内核层运行代码，运行结束以后，从内核层出来到用户层时，再把数据加载回来。因此，频繁的系统调用效率很低。今天我们就系统调用层面来对内存操作做进一步的了解。 内存管理（Memory Management）系统调用brk()与sbrk()1234//函数原型：#include&lt;unistd.h&gt;int brk(void * addr); void * sbrk(intptr_t increment); 描述：brk()和sbrk()改变程序间断点的位置。程序间断点就是程序数据段的结尾。（程序间断点是为初始化数据段的起始位置）.通过增加程序间断点进程可以更有效的申请内存 。当addr参数合理、系统有足够的内存并且不超过最大值时brk()函数将数据段结尾设置为addr,即间断点设置为addr。sbrk()将程序数据空间增加increment字节。当increment为0时则返回程序间断点的当前位置。 返回值：brk()成功返回0，失败返回-1并且设置errno值为ENOMEM（注：在mmap中会提到）。sbrk()成功返回之前的程序间断点地址。如果间断点值增加，那么这个指针（指的是返回的之前的间断点地址）是指向分配的新的内存的首地址。如果出错失败，就返回一个指针并设置errno全局变量的值为ENOMEM。 总结：这两个函数都用来改变 “program break” (程序间断点)的位置，改变数据段长度（Change data segment size），实现虚拟内存到物理内存的映射。brk()函数直接修改有效访问范围的末尾地址实现分配与回收。sbrk()参数函数中：当increment为正值时，间断点位置向后移动increment字节。同时返回移动之前的位置，相当于分配内存。当increment为负值时，位置向前移动increment字节，相当与于释放内存，其返回值没有实际意义。当increment为0时，不移动位置只返回当前位置。参数increment的符号决定了是分配还是回收内存。而关于program break的位置如图所示： 简单测试对于分配好的内存，我们只要有其首地址old与长度MAX*MAX即可不越界的准确使用（如下图所示），其效果与malloc相同，只不过sbrk()与brk()是C标准函数的底层实现而已，其机制较为复杂（测试中，死循环是为了查看maps文件，不至于进程消亡文件随之消失）。 虽然，sbrk()与brk()均可分配回收兼职，但是我们一般用sbrk()分配内存，而用brk()回收内存，上例中回收内存可以这样写： 123456int err = brk(old);/**或者brk(p);效果与sbrk(-MAX*MAX);是一样的，但brk()更方便与清晰明了。**/if(-1 == err)&#123; perror(&quot;brk&quot;); exit(EXIT_FAILURE);&#125; 2、mmap()与munmap():mmap函数（地址映射）：mmap将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零(Linux堆空间未使用内存均清零)。这里我们只研究mmap的内存映射，而暂时不讨论文件方面的问题。关于mmap的文件映射的更详细的内容可参考认真分析mmap：是什么 为什么 怎么用 123//函数原型：#incldue&lt;sys/mman.h&gt;void * mmap(void * addr, size_t length,int prot,int flags,int fd,off_t offset) 12345678910111213141516171819202122232425262728参数：（1）、addr: 起始地址，置零让系统自行选择并返回即可. （2）、length: 长度，不够一页会自动凑够一页的整数倍，我们可以宏定义#define MIN_LENGTH_MMAP 4096为一页大小 （3）、prot: 读写操作权限，PROT_READ可读、PROT_WRITE可写、PROT_EXEC可执行、PROT_NONE映射区域不能读取。（注意PROT_XXXXX与文件本身的权限不冲突，如果在程序中不设定任何权限，即使本身存在读写权限，该进程也不能对其操作） （4）、flags常用标志: ①MAP_SHARED【share this mapping】、MAP_PRIVATE【Create a private copy-on-write mapping】 MAP_SHARED只能设置文件共享，不能地址共享，即使设置了共享，对于两个进程来说，也不会生效。而MAP_PRIVATE则对于文件与内存都可以设置为私有。 ②MAP_ANON【Deprecated】、MAP_ANONYMOUS：匿名映射，如果映射地址需要加该参数，如果不加默认映射文件。MAP_ANON已经过时，只需使用MAP_ANONYMOUS即可 （5）、文件描述符：fd （6）、文件描述符偏移量：offset （fd和offset对于一般性内存分配来说设置为0即可）返回值：失败返回MAP_FAILED，即(void * (-1))并设置errno全局变量。 成功返回指向mmap area的指针pointer。常见errno错误：①ENOMEM：内存不足； ②EAGAIN：文件被锁住或有太多内存被锁住； ③EBADF：参数fd不是有效的文件描述符； ④EACCES：存在权限错误，。如果是MAP_PRIVATE情况下文件必须可读；使用MAP_SHARED则文件必须能写入，且设置prot权限必须为PROT_WRITE。 ⑤EINVAL：参数addr、length或者offset中有不合法参数存在。 12munmap函数：解除映射关系int munmap(void * addr, size_t length);//addr为mmap函数返回接收的地址，length为请求分配的长度。 常用管理命令本节介绍了管理 Linux 的虚拟内存的常用命令，更多可参考：linux内存查看方法 查看系统内存状态查看系统内存情况的方式有很多，free、 vmstat等命令都可输出当前系统的内存状态，需要注意的是可用内存并不只是 free 这一列，由于操作系统的 lazy 特性，大量的 buffer/cache 在进程不再使用后，不会被立即清理，如果之前使用它们的进程再次运行还可以继续使用，它们在必要时也是可以被利用的。 此外，通过 cat /proc/meminfo 可以查看系统内存被使用的详细情况，包括脏页状态等。详情可参见：/PROC/MEMINFO之谜。 pmap如果想单独查看某一进程的虚拟内存分布情况，可以使用 pmap pid 命令，它会把虚拟内存各段的占用情况从低地址到高地址都列出来。 可以添加 -XX 参数来输出更详细的信息。 ##参考： 深入理解Linux中内存管理：https://www.cnblogs.com/lcw/p/3505503.html 理解 Linux 的虚拟内存：https://zhenbianshu.github.io/2018/11/understand_virtual_memory.html Linux虚拟地址空间布局 系统调用与内存管理（sbrk、brk、mmap、munmap）","categories":[],"tags":[{"name":"linux 虚拟内存 内存管理 c内存模型","slug":"linux-虚拟内存-内存管理-c内存模型","permalink":"https://hesitationpencil.github.io/tags/linux-虚拟内存-内存管理-c内存模型/"}]},{"title":"FFmpeg命令详解","slug":"FFmpeg命令详解 ","date":"2019-06-20T07:19:14.000Z","updated":"2019-06-20T07:58:00.703Z","comments":true,"path":"2019/06/20/FFmpeg命令详解 /","link":"","permalink":"https://hesitationpencil.github.io/2019/06/20/FFmpeg命令详解 /","excerpt":"","text":"滤镜解析FFmpeg中filter分为： audio filter video filter Multimedia filter source filter（仅输出） sink filter（仅输入） 详细的滤镜说明参看：https://ffmpeg.org/ffmpeg-filters.html 视频滤镜crop按照特定分辨率裁剪输入视频 截取右下角1/4的区块：crop=in_w/2:in_h/2:in_w/2:in_h/2 scale使用libswscale库完成视频缩放的filter 宽高缩小一半 scale=in_w/2:in_h/2 宽高固定拉伸比例：scale=1400:900::force_original_aspect_ratio=decrease pad视频边界填充 不论输入视频分辨率，统一缩放成1280x720，并且居中展示: scale=1280:720:force_original_aspect_ratio=decrease, pad=1280:720:(1280-in_w)/2:(720-in_h)/2 overlay视频叠加 视频叠加在右下角，各空10px：overlay=main_w-overlay_w-10:main_h-overlay_h-10 rotate视频任意角度旋转 逆时针旋转1/6圆周：rotate=-PI/6 视频一直旋转：rotate=&#39;2*PI*t:ow=hypot(iw,ih):oh=ow&#39; hflip &amp; vflip水平和垂直镜像 edgedetect边缘检测 fps按照指定帧率输出视频帧（丢帧或者复制） drawbox绘制box 半透明框：drawbox=x=10:y=10:w=100:h=100:color=pink@0.5:t=max drawgrid绘制grid（表格） 3x3表格：drawgrid=w=iw/3:h=ih/3:t=2:c=white@0.5 drawtext绘制text，编译ffmpeg需要添加选项--enable-libfreetype 微软雅黑字体：drawtext=fontfile=/Users/xxx/fonts/MsYaHei.ttf:text=&#39;Hello 世界&#39;:x=50: y=500:fontsize=80: fontcolor=white blend &amp; tblend将两帧视频合并为一帧。 thumbnail提取缩略图。 transpose图像转置。 histogram生成每帧的各颜色分量的直方图。 showinfo显示视频帧的参数信息，比如时间戳、采样格式、帧类型等。 1、加字幕​ 命令：ffmpeg -i -filter_complex subtitles=filename=-y ​ 说明：利用libass来为视频嵌入字幕，字幕是直接嵌入到视频里的硬字幕。 2、剪切​ 命令：ffmpeg -i -ss 0 -t 10 -y ​ 说明：ss跟的是起始时间，t为持续时间，上面命令意思为从0秒开始截取10秒的时间。 3、缩放​ 命令： ffmpeg -i -filter_complex scale=320:240 -y ​ 说明：scale参数为宽高。 4、剪裁​ 命令：ffmpeg -i -filter_complex crop=320:240:0:0 -y ​ 说明：其中的 crop=320:240:0:0为裁剪参数，具体含义是 crop=width:height:x:y，其中 width 和 height 表示裁剪后的尺寸，x:y 表示裁剪区域的左上角坐标。 5、加水印命令：ffmpeg -i src.avi -vf “movie=[logo];[in][logo]overlay=100:100[out]”-y ​ 说明：LogoName为图片名，overlay=100:100意义为overlay=x:y，在(x,y)坐标处开始添加水印。 ​ 左上角：overlay=10:10 ​ 右上角：overlay=main_w-overlay_w-10:10 ​ 左下角：overlay=10:main_h-overlay_h-10 ​ 右下角：overlay=main_w-overlay_w-10:main_h-overlay_h-10 6、拼接视频​ 命令： ​ 第一步：ffmpeg -i INPUT -fmpeg OUTPUT ​ 第二步：copy /b INPUT+INPUT OUTPUT ​ 第三步：ffmpeg -i INPUT -f FORMAT OUTPUT ​ 说明：第一步把输入文件转为相同格式，第二步利用copy命令把文件合并，第三步把合并文件转为最终结果视频。 ​ 例：把名为test.avi、test1_2.mp4 两个视频合并为resu.avi。 ​ 第一步：ffmpeg -itest1.avi test1.mpg ​ ffmpeg-i test1_2.mp4 test2.mpg ​ 第二步：copy /btest1.mpg+test2.mpg resu.mpge ​ 第三步：ffmpeg -iresu.mpge -y resu.avi 7、旋转​ 命令： ffmpeg -i -filter_complex transpose=X -y ​ 说明：transpose=1为顺时针旋转90°，transpose=2逆时针旋转90°。 8、镜像​ 上下镜像 ​ 命令：ffmpeg -i src.avi -vf “split[mian][tmp];[tmp]crop=iw:ih/2:0:0,vflip[flip];[mian][flip]overlay=0:H/2”-y GHO.avi ​ 说明：从命令中可以看出crop和vflip在一条流水线上，他们的处理流程如下图所示： 可以利用此filter来做上下颠倒，命令如下： ffmpeg-i src.avi -vf “split [main][tmp]; [tmp] crop=iw:ih:0:0, vflip [flip];[main][flip] overlay=0:0” GHO2.avi 处理效果和 命令ffmpeg -isrc.avi -vf vflip GHO_v_1.avi一样， 这样写只是为了更好的理解filter处理链。 ​ 左右镜像 ​ 命令： ffmpeg -i src.avi-vf “split [main][tmp]; [tmp] crop=iw/2:ih:0:0, hflip [flip]; [main][flip]overlay=W/2:0” GHO_H.avi ​ 说明：流程和上下镜像一样，只是把坐标换了，并且指定用名为hfilp的filter。 ​ 可以利用此filter来做左右颠倒，命令如下： ffmpeg-i src.avi -vf “split [main][tmp ]; [tmp] crop=iw:ih:0:0, hflip [flip];[main][flip] overlay=W:0” GHO_H_1.avi和命令ffmpeg -i src.avi-vf hflip GHO_H_1.avi一样的效果，这样写只是为了更好的理解filter处理链。 ​ 小结：split过滤器把输入分裂为2路输出，crop过滤器为翻转选取图像范围，vflip和hflip过滤器把crop切下的图像翻转（垂直、水平），overlay过滤器指定坐标来贴经过翻转处理的图像。 ​ 9、加黑边​ 命令： ffmpeg -isrc.avi -vf pad=1280:800:0:40:black -y test_pad.avi ​ 说明：pad=width:high:x:y:coler，这里的宽和高指的是结果视频尺寸（包含加黑边的尺寸），XY指的是源视频添加到结果视频所在位置，coler为填充颜色。 10、调音量​ 命令：ffmpeg -i -vol X ​ 说明：不解释","categories":[],"tags":[{"name":"音视频 ffmpeg","slug":"音视频-ffmpeg","permalink":"https://hesitationpencil.github.io/tags/音视频-ffmpeg/"}]},{"title":"apk签名过程及多渠道","slug":"apk签名及多渠道打包","date":"2019-06-20T07:19:14.000Z","updated":"2019-06-20T07:55:23.896Z","comments":true,"path":"2019/06/20/apk签名及多渠道打包/","link":"","permalink":"https://hesitationpencil.github.io/2019/06/20/apk签名及多渠道打包/","excerpt":"","text":"apk签名过程及多渠道公司业务渠道较多共有70多个渠道，打包时间较长，所以抽时间研究一下美团的多渠道打包。本文介绍常见的多渠道打包方式：productFlavors方式，apktool,美团1.0，美团2.0,腾讯 这些方式技术从旧到新，试图说起多渠道打包的脉络。 productFlavorsproductFlavors不用切换项目分支就可以编译调试不同项目版本的APK，并且可以快速打包所有项目版本的APK。例如是开发第三方Android OS的时候，由于要给不同的厂商做定制，并且适配不同的硬件平台，所以发版本的时候，经常要切换项目分支，然后逐个编译APK。关于更多productFlavor介绍参考：productFlavors详细使用 productFlavors多渠道打包具体详情参见：Gradle实战：Android多渠道打包方案汇总 早期的多渠道打包基本上是采用这种方式。首先，在AndroidManifest.xml中添加渠道信息占位符： 1&lt;meta-data android:name=&quot;InstallChannel&quot; android:value=&quot;$&#123;InstallChannel&#125;&quot; /&gt; 然后，通过Gradle Plugin提供的productFlavors标签，添加渠道信息： 12345678productFlavors&#123; &quot;YingYongBao&quot;&#123; manifestPlaceholders = [InstallChannel : &quot;YingYongBao&quot;] &#125; &quot;360&quot;&#123; manifestPlaceholders = [InstallChannel : &quot;360&quot;] &#125;&#125; 这样，Gradle编译生成多渠道包时，会用不同的渠道信息替换AndroidManifest.xml中的占位符。我们在代码中，也就可以直接读取AndroidManifest.xml中的渠道信息了。 但是，这种方式存在一些缺点： 每生成一个渠道包，都要重新执行一遍构建流程，效率太低，只适用于渠道较少的场景。 Gradle会为每个渠道包生成一个不同的BuildConfig.java类，记录渠道信息，导致每个渠道包的DEX的CRC值都不同。一般情况下，这是没有影响的。但是如果你使用了微信的Tinker热补丁方案，那么就需要为不同的渠道包打不同的补丁，这完全是不可以接受的。（因为Tinker是通过对比基础包APK和新包APK生成差分补丁，然后再把补丁和基础包APK一起合成新包APK。这就要求用于生成差分补丁的基础包DEX和用于合成新包的基础包DEX是完全一致的，即：每一个基础渠道包的DEX文件是完全一致的，不然就会合成失败） 针对上述问题市面上出现了很多第三方，其中比较突出的是apktool,mcxiaoke的packer-ng-plugin，美图的walle和腾讯的VasDolly apk签名过程及多渠道方案现市面上存在的多渠道打包方式的原理大都是改apk文件，如此会造成签名验证问题。如此要掌握多渠道，需要先了解apk的签名过程。apk的签名先后有v1,v2,v3三种。 签名相关的基础知识在了解apk的签名方式之前，我们先要了解签名相关的基础知识 数据摘要数据摘要算法是一种能产生特定输出格式的算法，其原理是根据一定的运算规则对原始数据进行某种形式的信息提取，被提取出的信息就是原始数据的消息摘要，也称为数据指纹。一般情况下，数据摘要算法具有以下特点： 无论输入数据有多大（长），计算出来的数据摘要的长度总是固定的。例如：MD5算法计算出的数据摘要有128Bit。一般情况下（不考虑碰撞的情况下），只要原始数据不同，那么其对应的数据摘要就不会相同。 同时，只要原始数据有任何改动，那么其数据摘要也会完全不同。即：相同的原始数据必有相同的数据摘要，不同的原始数据，其数据摘要也必然不同。 不可逆性 即只能正向提取原始数据的数据摘要，而无法从数据摘要中恢复出原始数据。著名的摘要算法有RSA公司的MD5算法和SHA系列算法。数字签名和数字证书数字签名和数字证书是成对出现的，两者不可分离（数字签名主要用来校验数据的完整性，数字证书主要用来确保公钥的安全发放）。要明白数字签名的概念，必须要了解数据的加密、传输和校验流程。一般情况下，要实现数据的可靠通信，需要解决以下两个问题： 确定数据的来源是其真正的发送者。 确保数据在传输过程中，没有被篡改，或者若被篡改了，可以及时发现。 而数字签名，就是为了解决这两个问题而诞生的。首先，数据的发送者需要先申请一对公私钥对，并将公钥交给数据接收者。然后，若数据发送者需要发送数据给接收者，则首先要根据原始数据，生成一份数字签名，然后把原始数据和数字签名一起发送给接收者。数字签名由以下两步计算得来： 计算发送数据的数据摘要 用私钥对提取的数据摘要进行加密这样，数据接收者拿到的消息就包含了两块内容： 原始数据内容 附加的数字签名 接下来，接收者就会通过以下几步，校验数据的真实性： 用相同的摘要算法计算出原始数据的数据摘要。 用预先得到的公钥解密数字签名。 对比签名得到的数据是否一致，如果一致，则说明数据没有被篡改，否则数据就是脏数据了 因为私钥只有发送者才有，所以其他人无法伪造数字签名。这样通过数字签名就确保了数据的可靠传输。综上所述，数字签名就是只有发送者才能产生的别人无法伪造的一段数字串，这段数字串同时也是对发送者发送数据真实性的一个有效证明。 想法虽好，但是上面的整个流程，有一个前提，就是数据接收者能够正确拿到发送者的公钥。如果接收者拿到的公钥被篡改了，那么坏人就会被当成好人，而真正的数据发送者发送的数据则会被视作脏数据。那怎么才能保证公钥的安全性那？这就要靠数字证书来解决了。 数字证书是由有公信力的证书中心（CA）颁发给申请者的证书，主要包含了：证书的发布机构、证书的有效期、申请者的公钥、申请者信息、数字签名使用的算法，以及证书内容的数字签名。 可见，数字证书也用到了数字签名技术。只不过签名的内容是数据发送方的公钥，以及一些其它证书信息。这样数据发送者发送的消息就包含了三部分内容： 原始数据内容 附加的数字签名 申请的数字证书。 接收者拿到数据后，首先会根据CA的公钥，解码出发送者的公钥。然后就与上面的校验流程完全相同了。 所以，数字证书主要解决了公钥的安全发放问题。因此，包含数字证书的整个签名和校验流程如下图所示： V1签名和多渠道打包方案在android 7.0（N）之前是这种。 V1签名机制默认情况下，APK使用的就是V1签名。解压APK后，在META-INF目录下，可以看到三个文件：MANIFEST.MF、CERT.SF、CERT.RSA。它们都是V1签名的产物。 其中，MANIFEST.MF文件内容如下所示： 它记录了APK中所有原始文件的数据摘要的Base64编码,而数据摘要算法就是SHA1。 CERT.SF文件内容如下所示： SHA1-Digest-Manifest-Main-Attributes主属性记录了MANIFEST.MF文件所有主属性的数据摘要的Base64编码。SHA1-Digest-Manifest则记录了整个MANIFEST.MF文件的数据摘要的Base64编码。其余的普通属性则和MANIFEST.MF中的属性一一对应，分别记录了对应数据块的数据摘要的Base64编码。例如：CERT.SF文件中skin_drawable_btm_line.xml对应的SHA1-Digest，就是下面内容的数据摘要的Base64编码。 123Name: res/drawable/skin_drawable_btm_line.xmlSHA1-Digest: JqJbk6/AsWZMcGVehCXb33Cdtrk=\\r\\n 这里要注意的是：最后一行的换行符是必不可少，需要参与计算的。 CERT.RSA文件包含了对CERT.SF文件的数字签名和开发者的数字证书。RSA就是计算数字签名使用的非对称加密算法。 V1签名的详细流程可参考SignApk.java，整个签名流程如下图所示： 整个签名机制的最终产物就是MANIFEST.MF、CERT.SF、CERT.RSA三个文件。 v1校验流程在安装APK时，Android系统会校验签名，检查APK是否被篡改。代码流程是：PackageManagerService.java -&gt; PackageParser.java，PackageParser类负责V1签名的具体校验。整个校验流程如下图所示： 若中间任何一步校验失败，APK就不能安装。 OK，了解了V1的签名和校验流程。我们来看下，V1签名是怎么保证APK文件不被篡改的？首先，如果破坏者修改了APK中的任何文件，那么被篡改文件的数据摘要的Base64编码就和MANIFEST.MF文件的记录值不一致，导致校验失败。其次，如果破坏者同时修改了对应文件在MANIFEST.MF文件中的Base64值，那么MANIFEST.MF中对应数据块的Base64值就和CERT.SF文件中的记录值不一致，导致校验失败。最后，如果破坏者更进一步，同时修改了对应文件在CERT.SF文件中的Base64值，那么CERT.SF的数字签名就和CERT.RSA记录的签名不一致，也会校验失败。那有没有可能继续伪造CERT.SF的数字签名那？理论上不可能，因为破坏者没有开发者的私钥。那破坏者是不是可以用自己的私钥和数字证书重新签名那，这倒是完全可以！ 综上所述，任何对在MANIFEST.MF中有对应数字摘要的文件修改都会导致签名失败，除非重新签名。任何对在MANIFEST.MF文件的修改也会导致签名失败。如此针对v1我们可以从以下3个方面下手避免添加渠道信息后导致签名失败。 添加不被签名包含的文件写入多渠道信息。我们发现在META-INF中新建的文件是不会改变签名结构的，如此可知META-INF中新建文件写入渠道信息，其中美团的第一代打包工具是这样做的。 我们可以通过逆向手段，添加渠道信息。即解压apk，添加渠道信息，重新签名。市面上apktool是这样弄的 修改apk文件。我们发现v1的apk分三部分:内容快，中央目录块和中央结束块(EOCD)，其中EOCD是生成apk时自动加进去的，不受签名保护，如此可在其中添加渠道信息。市面上mcxiaoke的packer-ng-plugin和腾讯的VasDolly是采用这种原理 apktoolApkTool是一个逆向分析工具，可以把APK解开，添加代码后，重新打包成APK，当然这些都是通过脚本实现的。因此，基于ApkTool的多渠道打包方案分为以下几步： 复制一份新的APK通过ApkTool工具，解压APK（apktool d origin.apk）删除已有签名信息添加渠道信息（可以在APK的任何文件添加渠道信息）通过ApkTool工具，重新打包生成新APK（apktool b newApkDir）重新签名经过测试，这种方案完全是可行的。 优点：不需要重新构建新渠道包，仅需要复制修改就可以了。并且因为是重新签名，所以同时支持V1和V2签名。 缺点：ApkTool工具不稳定，曾经遇到过升级Gradle Plugin版本后，低版本ApkTool解压APK失败的情况。生成新渠道包时，需要重新解包、打包和签名，而这几步操作又是相对比较耗时的。经过测试：生成企鹅电竞10个渠道包需要16分钟左右，虽然比Gradle Plugin方案减少很多耗时。但是若需要同时生成上百个渠道包，则需要几个小时，显然不适合渠道非常多的业务场景。 修改apkapktool存在诸多缺点，针对v1我采用的还是添加文件和修改apk来添加渠道信息的。修改文件原理教简单，下面我们重点介绍修改apk apk文件结构修改apk得先知道其结构。APK文件本质上是一个ZIP压缩包，而ZIP格式是固定的，主要由三部分构成，如下图所示： 第一部分是内容块，所有的压缩文件都在这部分。每个压缩文件都有一个local file header，主要记录了文件名、压缩算法、压缩前后的文件大小、修改时间、CRC32值等。 第二部分称为中央目录，包含了多个central directory file header（和第一部分的local file header一一对应），每个中央目录文件头主要记录了压缩算法、注释信息、对应local file header的偏移量等，方便快速定位数据。 最后一部分是EOCD，主要记录了中央目录大小、偏移量和ZIP注释信息等，其详细结构如下图所示： 根据之前的V1签名和校验机制可知，V1签名只会检验第一部分的所有压缩文件，而不理会后两部分内容。因此，只要把渠道信息写入到后两块内容就可以通过V1校验，而EOCD的注释字段无疑是最好的选择。 向apk文件结构中写入渠道信息既然找到了突破口，那么基于V1签名的多渠道打包方案就应运而生：在APK文件的注释字段，添加渠道信息。 整个方案包括以下几步： 复制APK 找到EOCD数据块 修改注释长度 添加渠道信息 添加渠道信息长度 添加魔数添加渠道信息后的EOCD数据块如下所示： 这里添加魔数的好处是方便从后向前读取数据，定位渠道信息。因此，读取渠道信息包括以下几步： 定位到魔数 向前读两个字节，确定渠道信息的长度LEN 继续向前读LEN字节，就是渠道信息了。 通过16进制编辑器，可以查看到添加渠道信息后的APK（小端模式），如下所示： 6C 74 6C 6F 76 75 7A 68是魔数，04 00表示渠道信息长度为4，6C 65 6F 6E就是渠道信息leon了。0E 00就是APK注释长度了，正好是15。 虽说整个方案很清晰，但是在找到EOCD数据块这步遇到一个问题。如果APK本身没有注释，那最后22字节就是EOCD。但是若APK本身已经包含了注释字段，那怎么确定EOCD的起始位置那？这里借鉴了系统V2签名确定EOCD位置的方案。整个计算流程如下图所示： 整个方案介绍完了，该方案的最大优点就是：不需要解压缩APK，不需要重新签名，只需要复制APK，在注释字段添加渠道信息。每个渠道包仅需几秒的耗时，非常适合渠道较多的APK。 但是好景不长，Android7.0之后新增了V2签名，该签名会校验整个APK的数据摘要，导致上述渠道打包方案失效。所以如果想继续使用上述方案，需要关闭Gradle Plugin中的V2签名选项，禁用V2签名。 V2签名和多渠道打包方案为什么需要V2签名从前面的V1签名介绍，可以知道V1存在两个弊端： MANIFEST.MF中的数据摘要是基于原始未压缩文件计算的。因此在校验时，需要先解压出原始文件，才能进行校验。而解压操作无疑是耗时的。 V1签名仅仅校验APK第一部分中的文件，缺少对APK的完整性校验。因此，在签名后，我们还可以修改APK文件，例如：通过zipalign进行字节对齐后，仍然可以正常安装。 正是基于这两点，Google提出了V2签名，解决了上述两个问题： V2签名是对APK本身进行数据摘要计算，不存在解压APK的操作，减少了校验时间。 V2签名是针对整个APK进行校验（不包含签名块本身），因此对APK的任何修改（包括添加注释、zipalign字节对齐）都无法通过V2签名的校验。关于第一点的耗时问题，这里有一份实验室数据（Nexus 6P、Android 7.1.1）可供参考。 APK安装耗时对比 取5次平均耗时（秒） V1签名APK 11.64 V2签名APK 4.42 可见，V2签名对APK的安装速度还是提升不少的。 V2签名机制不同于V1，V2签名会生成一个签名块，插入到APK中。因此，V2签名后的APK结构如下图所示： APK签名块位于中央目录之前，文件数据之后。V2签名同时修改了EOCD中的中央目录的偏移量，使签名后的APK还符合ZIP结构。 APK签名块的具体结构如下图所示： 首先是8字节的签名块大小，此大小不包含该字段本身的8字节； 其次就是ID-Value序列，就是一个4字节的ID和对应的数据； 然后又是一个8字节的签名块大小，与开始的8字节是相等的；最后是16字节的签名块魔数。 其中，ID为0x7109871a对应的Value就是V2签名块数据。 V2签名块的生成可参考ApkSignerV2，整体结构和流程如下图所示： 首先，根据多个签名算法，计算出整个APK的数据摘要，组成左上角的APK数据摘要集； 接着，把最左侧一列的数据摘要、数字证书和额外属性组装起来，形成类似于V1签名的“MF”文件（第二列第一行）； 其次，再用相同的私钥，不同的签名算法，计算出“MF”文件的数字签名，形成类似于V1签名的“SF”文件（第二列第二行）； 然后，把第二列的类似MF文件、类似SF文件和开发者公钥一起组装成通过单个keystore签名后的v2签名块（第三列第一行）。 最后，把多个keystore签名后的签名块组装起来，就是完整的V2签名块了（Android中允许使用多个keystore对apk进行签名）。 上述流程比较繁琐。简而言之，单个keystore签名块主要由三部分组成，分别是上图中第二列的三个数据块：类似MF文件、类似SF文件和开发者公钥，其结构如下图所示： 除此之外，Google也优化了计算数据摘要的算法，使得可以并行计算，如下图所示： 数据摘要的计算包括以下几步： 首先，将上述APK中文件内容块、中央目录、EOCD按照1MB大小分割成一些小块。 然后，计算每个小块的数据摘要，基础数据是0xa5 + 块字节长度 + 块内容。 最后，计算整体的数据摘要，基础数据是0x5a + 数据块的数量 + 每个数据块的摘要内容。 这样，每个数据块的数据摘要就可以并行计算，加快了V2签名和校验的速度。 V2校验流程Android Gradle Plugin2.2之上默认会同时开启V1和V2签名，同时包含V1和V2签名的CERT.SF文件会有一个特殊的主属性，如下图所示： 该属性会强制APK走V2校验流程（7.0之上），以充分利用V2签名的优势（速度快和更完善的校验机制）。因此，同时包含V1和V2签名的APK的校验流程如下所示： 简而言之：优先校验V2，没有或者不认识V2，则校验V1。 这里引申出另外一个问题：APK签名时，只有V2签名，没有V1签名行不行？经过尝试，这种情况是可以编译通过的，并且在Android 7.0之上也可以正确安装和运行。但是7.0之下，因为不认识V2，又没有V1签名，所以会报没有签名的错误。 OK，明确了Android平台对V1和V2签名的校验选择之后，我们来看下V2签名的具体校验流程（PackageManagerService.java -&gt; PackageParser.java-&gt; ApkSignatureSchemeV2Verifier.java），如下图所示： 其中，最强签名算法是根据该算法使用的数据摘要算法来对比产生的，比如：SHA512 &gt; SHA256。 校验成功的定义是至少找到一个keystore对应的签名块，并且所有签名块都按照上述流程校验成功。 下面我们来看下V2签名是怎么保证APK不被篡改的？ 首先，如果破坏者修改了APK文件的任何部分（签名块本身除外），那么APK的数据摘要就和“MF”数据块中记录的数据摘要不一致，导致校验失败。 其次，如果破坏者同时修改了“MF”数据块中的数据摘要，那么“MF”数据块的数字签名就和“SF”数据块中记录的数字签名不一致，导致校验失败。 然后，如果破坏者使用自己的私钥去加密生成“SF”数据块，那么使用开发者的公钥去解密“SF”数据块中的数字签名就会失败； 最后，更进一步，若破坏者甚至替换了开发者公钥，那么使用数字证书中的公钥校验签名块中的公钥就会失败，这也正是数字证书的作用。 综上所述，任何对APK的修改，在安装时都会失败，除非对APK重新签名。但是相同包名，不同签名的APK也是不能同时安装的。 其实也很简单，原来Android系统在校验APK的数据摘要时，首先会把EOCD的中央目录偏移量替换成签名块的偏移量，然后再计算数据摘要。而签名块的偏移量不就是v2签名之前的中央目录偏移量嘛！！！，因此，这样计算出的数据摘要就和“MF”数据块中的数据摘要完全一致了。具体代码逻辑，可参考ApkSignatureSchemeV2Verifier.java的416 ~ 420行 基于V2签名的多渠道打包方案在上节V2签名的校验流程中，有一个很重要的细节：Android系统只会关注ID为0x7109871a的V2签名块，并且忽略其他的ID-Value，同时V2签名只会保护APK本身，不包含签名块。 因此，基于V2签名的多渠道打包方案就应运而生：在APK签名块中添加一个ID-Value，存储渠道信息。 整个方案包括以下几步： 找到APK的EOCD块 找到APK签名块 获取已有的ID-Value Pair 添加包含渠道信息的ID-Value 基于所有的ID-Value生成新的签名块 修改EOCD的中央目录的偏移量（上面已介绍过：修改EOCD的中央目录偏移量，不会导致数据摘要校验失败） 用新的签名块替代旧的签名块，生成带有渠道信息的APK 实际上，除了渠道信息，我们可以在APK签名块中添加任何辅助信息。 通过16进制编辑器，可以查看到添加渠道信息后的APK（小端模式），如下所示： V3签名和多渠道打包方案在android 9.0(N)引入的 为什么要有v3主要是为了换签名 生成签名的时，可以指定一个有效时间，这个时间默认为 25 年，并且 Google Play 也有硬性规定，上架的 App 签名有效期必须在 2033-10-22 日期之后。所以只要不是手欠修改了这个有效期，在当下这个时刻，是不会有问题，毕竟到现在还没有一款 App 存在 25 年。当然还有可能是公司被收购 需要改签名有些问题不在眼前，却是真实存在的。对于一款上架的 App，最重要的就是用户，而当签名失效之后，我们只能被迫换签名，此时因为签名校验无法通过，就会导致旧用户无法覆盖安装。这些历史用户唯一的选择，就是卸载后重新安装。好在这不仅仅是你我的问题，天塌下来有个子高的顶着，所以别担心，Google 已经着手在解决这个问题了。 v3签名块结构v3版本签名块也分成同样的三部分，与v2不同的是在SignerData部分，v3新增了attr块，其中是由更小的level块组成。每个level块中可以存储一个证书信息。前一个level块证书验证下一个level证书，以此类推。最后一个level块的证书，要符合SignerData中本身的证书，即用来签名整个APK的公钥所属于的证书。两个版本的签名块结构如下： v3验证签名流程因为签名的验证就是发生在一个apk包的安装过程中，所以为了更清楚验证签名的时机，有必要了解整个安装的分类与大致流程。Android安装应用主要有如下四种方式： 系统应用安装：开机时完成，没有安装界面 网络下载的应用安装：通过市场应用完成，没有安装界面 ADB工具安装：没有安装界面 第三方应用安装：通过packageinstall.apk应用安装，有安装界面 但是其实无论通过哪种方式安装都要通过PackageManagerService来完成安装的主要工作，最终在PMS中会去验证签名信息，流程如下 安装过程中如果发现有v3签名块，则必须使用v3签名的验证机制，不能绕过。否则才使用v2签名的验证机制，以此类推。 验证完整性数据完整性校验v3与v2版本相同，原理如下： 签名块包括对apk第一部分，第二部分，第三部分的二进制内容做加密保护，摘要算法以及签名算法。签名块本身不做加密，这里需要特殊注意的是由于第三部分包含了对第二部分的引用偏移，因此如果签名块做了改变，比如在签名过程中增加一种签名算法，或者增加签名者等信息就会导致这个引用偏移发生改变，因此在算摘要的时候需要剔除这个因素要以第三部分对签名块的偏移来做计算。 验证证书v2版本签名验证证书步骤： 利用PublicKey解密Signature，得到SignerData的hash明文 计算SignerData的hash值 两个值进行比较，如果相同则认为APK没有被修改过，解析出SignerData中的证书。否则安装失败 如果是第一次安装，直接将证书保存在应用信息中 如果是更新安装，即设备中原来存在这个应用，验证之前的证书是否与本次解析的证书相同。若相同，则安装成功，否则失败 v3版本签名验证证书步骤：（前三步同v2） 利用PublicKey解密Signature，得到SignerData的hash明文 计算SignerData的hash值 两个值进行比较，如果相同则认为APK没有被修改过，解析出SignerData中的证书。否则安装失败 逐个解析出level块证书并验证，并保存为这个应用的历史证书 如果是第一次安装，直接将证书与历史证书一并保存在应用信息中 如果是更新安装，验证之前的证书与历史证书，是否与本次解析的证书或者历史证书中存在相同的证书，其中任意一个证书符合即可安装 新特性场景举例其实就是当开发者需要更换证书时，即可直接用新证书新的私钥进行签名。不过为了让老应用相信新的证书，则需要用老证书来保证。举个例子，有两个level块：level 1与level 2： level 1放置老证书的信息 level 2中放置新证书的信息以及这段数据的签名 level 2中的签名是由老私钥进行签名的，则需要用老证书的公钥来验证 校验原来的证书与level 1 相同，则相信本次更新的level 2 的证书，即签名APK的证书 完成安装并记录新证书信息 v3多渠道方案略 原理和v2同 参考： https://www.jianshu.com/p/332525b09a88https://github.com/Meituan-Dianping/walle/https://segmentfault.com/a/1190000015554496https://juejin.im/entry/5a586bfaf265da3e2c3808c5https://blog.csdn.net/u010818425/article/details/52319382https://github.com/Tencent/VasDollyhttps://cloud.tencent.com/developer/article/1004884http://picksomething.cn/2018/05/08/Android%E5%A4%9A%E6%B8%A0%E9%81%93%E6%89%B9%E9%&gt;87%8F%E6%89%93%E5%8C%85%EF%BC%8C%E6%94%AF%E6%8C%81%E5%8F%8B%E7%9B%9F%E5%92%8C%E7%AC%&gt;AC%E4%B8%89%E6%96%B9%E5%8A%A0%E5%9B%BA/http://twei.site/2016/08/31/MarkdownPad-2-%E6%94%AF%E6%8C%81%E8%A1%A8%E6%A0%BC/","categories":[],"tags":[{"name":"打包原理","slug":"打包原理","permalink":"https://hesitationpencil.github.io/tags/打包原理/"}]},{"title":"增量更新","slug":"增量更新","date":"2019-06-20T07:19:14.000Z","updated":"2019-06-20T07:57:26.967Z","comments":true,"path":"2019/06/20/增量更新/","link":"","permalink":"https://hesitationpencil.github.io/2019/06/20/增量更新/","excerpt":"","text":"增量更新增量更新 一种不需要重新下载apk，利用新的apk在原有的基础生成patch包进行更新的一种技术。本文重增量更新的作用，原理和使用进行阐述。 原理及作用增量更新就是比较两个apk之间的二进制差异，生成patch包然后打入旧的apk里面从而达到生成新的apk。例如说：第一个版本是3M的apk ，第二个是8M的apk ，生成的patch包可能就在4M左右，甚至更小，但也不是单纯的两个apk相减的差值，有可能两个大小差不多的apk，生成patch包可能在1M左右，这个也是看包里的改动大小。生成的 patch下载到Android设备上跟较低版本的apk合成一个新版本的apk文件，如果不出意外的话，这个生成的apk和你之前做差分的apk是一致的。这么做就会为用户去节省很多的流量，就不会让用户去下载完整的apk，从而提高了用户体验。 使用 利用old.apk和new.apk生成增量文件（patch） 利用old.apk和patch生成new.apk 安装 需要实现增量更新，现在有各种开源的制作与合并差分包的开源库，比如：bsdiff、hdiff等等。因此我们只需要获得源码来使用即可。 增量文件的生成这里利用bsdiff工具做二进制的一个diff和patch了，可以直接下载工具window:https://github.com/cnSchwarzer/bsdiff-win/releases ubuntu:ubuntu sudo apt-get install bsdiff bisdiff算法原理尽可能多的利用old文件中已有的内容看，尽可能少的加入新的内容来构建new文件。通常的做法是对old文件和new文件做子字符串匹配或者使用hash技术，提取公共部分，将new文件中剩余的部分打包成patch包，在patch阶段中，用copying和insertion两个基本操作即可将old文件和patch包合成new文件。 ubuntu编译bisdiff下载ubuntu可自己编译bsdiff工具，先下载bisdiff和bzip2 bsdiff 下载地址： http://www.daemonology.net/bsdiff/ bsdiff 依赖bzip2(zip压缩库) https://nchc.dl.sourceforge.net/project/gnuwin32/bzip2/1.0.5/bzip2-1.0.5-src.zip 下载完后解压 bsdiff: 比较两个文件的二进制数据，生成差分包 bspatch： 合并旧的文件与差分包，生成新文件很显然，bspatch我们需要在Android环境下来执行，而bsdiff 一般会在你的存储服务器当中执行即电脑环境下执行(win或linux) 编译我们在目录下 直接 make 会产生错误需要修改makefile： 12345678910111213install: $&#123;INSTALL_PROGRAM&#125; bsdiff bspatch $&#123;PREFIX&#125;/bin.ifndef WITHOUT_MAN $&#123;INSTALL_MAN&#125; bsdiff.1 bspatch.1 $&#123;PREFIX&#125;/man/man1.endif#上面这段makefile片段显然有问题(指令必须以tab开头)#因此需要修改为：install: $&#123;INSTALL_PROGRAM&#125; bsdiff bspatch $&#123;PREFIX&#125;/bin .ifndef WITHOUT_MAN $&#123;INSTALL_MAN&#125; bsdiff.1 bspatch.1 $&#123;PREFIX&#125;/man/man1 .endif#也就是在 `.if` 和 `.endif` 前加一个 tab 修改后再来执行make 如果出现找不到bzip2 no file found bzlib.h之类的错误，则需要先安装bzip2： Ubuntu: install libbz2-dev ```1234&gt;&gt; Centos:&gt;&gt; ```yum -y install bzip2-devel.x86_64 Mac: install bzip2```12345678910111213141516171819&gt;&gt; &lt;!--install 不知道填什么，可以使用包管理器进行搜索： --&gt;&gt;&gt; &lt;!-- apt/yum/brew search bzip2 --&gt;如果执行make出现```shellbsdiff.c:(.text.startup+0x2aa): undefined reference to `BZ2_bzWriteOpen&apos;bsdiff.c:(.text.startup+0xcfa): undefined reference to `BZ2_bzWrite&apos;bsdiff.c:(.text.startup+0xe37): undefined reference to `BZ2_bzWrite&apos;bsdiff.c:(.text.startup+0xf80): undefined reference to `BZ2_bzWrite&apos;bsdiff.c:(.text.startup+0xfe1): undefined reference to `BZ2_bzWriteClose&apos;bsdiff.c:(.text.startup+0x1034): undefined reference to `BZ2_bzWriteOpen&apos;bsdiff.c:(.text.startup+0x105c): undefined reference to `BZ2_bzWrite&apos;bsdiff.c:(.text.startup+0x1082): undefined reference to `BZ2_bzWriteClose&apos;bsdiff.c:(.text.startup+0x10d5): undefined reference to `BZ2_bzWriteOpen&apos;bsdiff.c:(.text.startup+0x1100): undefined reference to `BZ2_bzWrite&apos;bsdiff.c:(.text.startup+0x1126): undefined reference to `BZ2_bzWriteClose&apos; 则修改Makefile为： 1234567891011121314151617CFLAGS += -O3 -lbz2PREFIX ?= /usr/localINSTALL_PROGRAM ?= $&#123;INSTALL&#125; -c -s -m 555INSTALL_MAN ?= $&#123;INSTALL&#125; -c -m 444all: bsdiff bspatchbsdiff: bsdiff.c cc bsdiff.c $&#123;CFLAGS&#125; -o bsdiff #增加bspatch: bspatch.c cc bspatch.c $&#123;CFLAGS&#125; -o bspatch #增加install: $&#123;INSTALL_PROGRAM&#125; bsdiff bspatch $&#123;PREFIX&#125;/bin .ifndef WITHOUT_MAN $&#123;INSTALL_MAN&#125; bsdiff.1 bspatch.1 $&#123;PREFIX&#125;/man/man1 .endif bsdiff可以通过如上编译使用，而bspatch则需要在Android工程中使用NDK来进行编译使用，工程地址： https://github.com/HesitationPencil/Study/tree/master/bsdiffdemo","categories":[],"tags":[{"name":"apk打包原理 增量更新","slug":"apk打包原理-增量更新","permalink":"https://hesitationpencil.github.io/tags/apk打包原理-增量更新/"}]},{"title":"屏幕适配","slug":"屏幕适配","date":"2019-06-20T07:19:14.000Z","updated":"2019-06-20T08:02:30.456Z","comments":true,"path":"2019/06/20/屏幕适配/","link":"","permalink":"https://hesitationpencil.github.io/2019/06/20/屏幕适配/","excerpt":"","text":"1.基本概念1.1 px简单说，像素就是表示一个点的RGB颜色；这个点，是数学上的概念，是没有大小的；但是屏幕显示一个像素是需要大小的，具体大小是屏幕尺寸除以屏幕分辨率 1.2 屏幕分辨率屏幕分辨率就是屏幕最多能显示多少个像素，如果屏幕最多能显示1080 * 1920个像素，屏幕大小是3 * 5英寸的，那么每个像素占用(3/1080) * (5/1920)的大小。一般情况下屏幕宽高比和像素宽高比是相等的， 1.2 ppi, dpi屏幕上每英寸上点的数量，我们叫做DPI（dots per inch），因为屏幕上面每个点对应一个像素，所以也有叫PPI；两者大部分情况可以混用，有时候又不一样。当DPI小的时候，每个点的物理尺寸就变大(点的大小理解为 DPI 分之一 英寸；比如DPI是160，每个点就是 1/160 英寸)；所以要解决屏幕颗粒大的问题，提高DPI值就可以了。但DPI提高后，又出现了另外一个问题：同样像素的Bitmap在新的屏幕上看起来小了。假设把DPI从160提高到320，原来160像素在新屏幕上的大小只有原来的一半。 1.3 dp,sp 因为在不同dpi下，相同像素下长度不一样，android引入了dp（density independent pixel），sp（Scale-independent Pixel）作为长度单位。简单粗暴直接规定一英寸就是160dp，即1dp=1/160inch;android内部帮我们做了1dp对应多少像素的换算，即（px=dp*(dpi/160)）,即1dp在dpi为160的设备上对应1px，在320dpi上对应2px。如此保证在相同dp下，在不同屏幕密度下显示一样的长度。 sp和dp很类似但唯一的区别是，Android系统允许用户自定义文字尺寸大小（小、正常、大、超大等等），当文字尺寸是“正常”时，1sp=1dp=1/160inch，而当文字尺寸是“大”或“超大”时，1sp=1sp*scale&gt;1/160inch。类似我们在windows里调整字体尺寸以后的效果——窗口大小不变，只有文字大小改变。1.3.1 dp的缺陷 dp解决了大小一致的问题，没解决比列的问题；如果我们设定控件的宽是160dp，在宽是3inch的屏幕上占比是1/3,在宽是4inch的屏幕上占比是1/4。 不精确；android会将实际dpi进行修正 然后根据density=dpi/160算出density，而px=density * dp；由此可知不是精确的，因为会修正。如实际屏幕密度为321dpi,参考下表知修正后的dpi为480，density为3。 名称 代表分辨率 范围 修正 density mdpi 320x480 120dpi~160dpi 160dpi 1 hdpi 480x800 160dpi~240dpi 240dpi 1.5 xhdpi 720x1280 240dpi~320dpi 320dpi 2 xxhdpi 1080x1920 320dpi~480dpi 480dpi 3 xxxhdpi 480dpi~640dpi 640dp 4 和美工的设计搞不对应。如设计师的图片基准是1080 * 1920，单位是px，如果图标是60px*60px，我们不能直接写60dp * 60dp，要根据屏幕密度换算成相应的dp。2.宽高限定符适配2.1好处宽高限定符解决了比列，不精确和 美工设计稿不对应三大问题。2.2使用做法就是穷举市面上所有的Android手机的宽高像素值： 设定一个基准的分辨率，其他分辨率都根据这个基准分辨率来计算，在不同的尺寸文件夹内部，根据该尺寸编写对应的dimens文件。比如以480x320为基准分辨率 宽度为320，将任何分辨率的宽度整分为320份，取值为x1-x320高度为480，将任何分辨率的高度整分为480份，取值为y1-y480 那么对于800480的分辨率的dimens文件来说，x1=(480/320)1=1.5pxx2=(480/320)*2=3px这个时候，如果我们的UI设计界面使用的就是基准分辨率，那么我们就可以按照设计稿上的尺寸填写相对应的dimens引用了,而当APP运行在不同分辨率的手机中时，这些系统会根据这些dimens引用去该分辨率的文件夹下面寻找对应的值。这样基本解决了我们的适配问题，而且极大的提升了我们UI开发的效率， 2.3缺陷 需要精准命中才能适配，比如1920x1080的手机就一定要找到1920x1080的限定符，否则就只能用统一的默认的dimens文件了。而使用默认的尺寸的话，UI就很可能变形，简单说，就是容错机制很差。 不适用于sp，当更改系统的字体大小时，字体大小不会改变。因为本质上还是用的px。 包体积大。因为市面上不同宽高的屏幕很多，这里尽可能的适配所有的话，会增大包的体积，采用这种方式包体积一般增大400kb~500kb3.代码适配3.1基本原理3.2常用的百分比库android-support-percent android官方的现已经弃用[AndroidAutoLayout](https://github.com/hongyangAndroid/AndroidAutoLayout)鸿洋的 已停止维护上面两个库都已经停止维护，现在推荐用ConstraintLayout替代。3.3缺陷 第三方的控件无效 老项目更改繁琐 设计图不匹配4.最小宽度限定符4.1 好处 解决了比列 教精确 如果有对应不上的情况，会向下找，这样的话失去了一部分精确性 对应美工设计稿。因为将屏幕分成美工给定的等分4.2 使用smallestWidth适配，或者叫sw限定符适配。指的是Android会识别屏幕可用高度和宽度的最小尺寸的dp值（其实就是手机的宽度值），然后根据识别到的结果去资源文件中寻找对应限定符的文件夹下的资源文件。这种机制和上文提到的宽高限定符适配原理上是一样的，都是系统通过特定的规则来选择对应的文件。举个例子，小米5的dpi是480,横向像素是1080px，根据px=dp(dpi/160)，横向的dp值是1080/(480/160),也就是360dp,系统就会去寻找是否存在value-sw360dp的文件夹以及对应的资源文件。smallestWidth限定符适配和宽高限定符适配最大的区别在于，前者有很好的容错机制，如果没有value-sw360dp文件夹，系统会向下寻找，比如离360dp最近的只有value-sw350dp，那么Android就会选择value-sw350dp文件夹下面的资源文件。这个特性就完美的解决了上文提到的宽高限定符的容错问题。这套方案是上述几种方案中最接近完美的方案。首先，从开发效率上，它不逊色于上述任意一种方案。根据固定的放缩比例，我们基本可以按照UI设计的尺寸不假思索的填写对应的dimens引用。我们还是以375个像素宽度的设计稿为例，在values-sw360dp文件夹下的diemns文件应该怎么编写呢？这个文件夹下，意味着手机的最小宽度的dp值是360，我们把360dp等分成375等份，每一个设计稿中的像素，大概代表smallestWidth值为360dp的手机中的0.96dp，那么接下来的事情就很简单了，假如设计稿上出现了一个10px*10px的ImageView,那么，我们就可以不假思索的在layout文件中写下对应的尺寸。而这种diemns引用，在不同的values-swdp文件夹下的数值是不同的，比如values-sw360dp和values-sw400dp,当系统识别到手机的smallestWidth值时，就会自动去寻找和目标数据最近的资源文件的尺寸。其次，从稳定性上，它也优于上述方案。原生的dp适配可能会碰到Pixel 2这种有些特别的手机需要单独适配，但是在smallestWidth适配中，通过计算Pixel 2手机的的smallestWidth的值是411，我们只需要生成一个values-sw411dp(或者取整生成values-sw410dp也没问题)就能解决问题。smallestWidth的适配机制由系统保证，我们只需要针对这套规则生成对应的资源文件即可，不会出现什么难以解决的问题，也根本不会影响我们的业务逻辑代码，而且只要我们生成的资源文件分布合理，，即使对应的smallestWidth值没有找到完全对应的资源文件，它也能向下兼容，寻找最接近的资源文件。4.3 缺陷 不适配android3.2一下版本。其是android3.2以后引入的 包体积过大。大约会增大300kb到800kb左右5.density适配今日头条开放出来的方案5.1优点 解决比列问题 解决设计图匹配问题 很精确 不影响包体积5.2使用5.2.1原理从dp和px的转换公式 ：px = dp * density 可以看出，如果设计图宽为360dp，想要保证在所有设备计算得出的px值都正好是屏幕宽度的话，我们只能修改 density 的值：5.3缺陷 如果有用到第三方库控件，则不适用。因为修改了系统的density值之后，整个布局的实际尺寸都会发生改变。6.其它（待更新） 参考：Android 屏幕适配方案一种极低成本的Android屏幕适配方式Android 目前最稳定和高效的UI适配方案","categories":[],"tags":[{"name":"适配","slug":"适配","permalink":"https://hesitationpencil.github.io/tags/适配/"}]},{"title":"android编舞者ChoreoGrapher","slug":"android编舞者ChoreoGrapher","date":"2019-06-20T07:19:14.000Z","updated":"2019-06-20T08:13:19.224Z","comments":true,"path":"2019/06/20/android编舞者ChoreoGrapher/","link":"","permalink":"https://hesitationpencil.github.io/2019/06/20/android编舞者ChoreoGrapher/","excerpt":"","text":"Choreographer的作用结合上篇Android 绘制原理可知道，屏幕每16ms 显示frame buffer上的帧信息，然后frame buffer和back buffer进行互换，并发送vsync信号，此时CPU会中断其它操作，来通过ChoreGrapher去确定显示的帧信息（控件应该怎么画，画在哪个位置，画多大），当这些信息确定后，GPU再根据这些信息刷新back buffer的信息，刷新完成后 back buffer 和 frame buffer互换位置。 Choreographer的具体运行过程Choreographer主要做如下工作，下面我们逐一分析 注册监听，当收到vsync信号，会回调 接受并保存控制帧的信息的任务 调用4个回调链表确定帧信息源码分析注册监听-FrameDisplayEventReceiverFrameDisplayEventReceiver是ChoreoGrapher的私有类，当收到vsync信号，且c/c++回调开关是打开的会调用FrameDisplayEventReceiver的onVsync()。FrameDisplayEventReceiver在Choreographer被创建，具体在第4行：123456789101112131415//frameworks/base/core/java/android/view/Choreographer.javaprivate Choreographer(Looper looper) &#123; mLooper = looper; mHandler = new FrameHandler(looper); mDisplayEventReceiver = USE_VSYNC ? new FrameDisplayEventReceiver(looper) : null; mLastFrameTimeNanos = Long.MIN_VALUE; mFrameIntervalNanos = (long) (1000000000 / getRefreshRate()); mCallbackQueues = new CallbackQueue[CALLBACK_LAST + 1]; for (int i = 0; i &lt;= CALLBACK_LAST; i++) &#123; mCallbackQueues[i] = new CallbackQueue(); &#125; &#125; FrameDisplayEventReceiver继承自DisplayEventReceiver，我们跟进去看构造方法，会发现调用了nativeInit()，这是个native方法： 1234567891011121314151617frameworks/base/core/java/android/view/DisplayEventReceiver.java/** * Creates a display event receiver. * * @param looper The looper to use when invoking callbacks. */ public DisplayEventReceiver(Looper looper) &#123; if (looper == null) &#123; throw new IllegalArgumentException(&quot;looper must not be null&quot;); &#125; mMessageQueue = looper.getQueue(); mReceiverPtr = nativeInit(new WeakReference&lt;DisplayEventReceiver&gt;(this), mMessageQueue); mCloseGuard.open(&quot;dispose&quot;); &#125; 通过FrameDisplayEventReceiver就是通过这个nativeInit()方法注册进去的。在nativeInit()中将我们java层传过来的DisplayEventReceiver和mMessageQueue 作为参数new了个NativeDisplayEventReceiver对象，然后调用NativeDisplayEventReceiver-&gt;initialize(). 12345678910111213141516171819//frameworks/base/core/jni/android_view_DisplayEventReceiver.cppstatic jlong nativeInit(JNIEnv* env, jclass clazz, jobject receiverWeak, jobject messageQueueObj) &#123; sp&lt;MessageQueue&gt; messageQueue = android_os_MessageQueue_getMessageQueue(env, messageQueueObj); if (messageQueue == NULL) &#123; jniThrowRuntimeException(env, &quot;MessageQueue is not initialized.&quot;); return 0; &#125; sp&lt;NativeDisplayEventReceiver&gt; receiver = new NativeDisplayEventReceiver(env, receiverWeak, messageQueue); status_t status = receiver-&gt;initialize(); if (status) &#123; String8 message; message.appendFormat(&quot;Failed to initialize display event receiver. status=%d&quot;, status); jniThrowRuntimeException(env, message.string()); return 0; &#125; 我们找到NativeDisplayEventReceiver构造方法 123456789frameworks/base/core/jni/android_view_DisplayEventReceiver.cppNativeDisplayEventReceiver::NativeDisplayEventReceiver(JNIEnv* env, jobject receiverWeak, const sp&lt;MessageQueue&gt;&amp; messageQueue) : DisplayEventDispatcher(messageQueue-&gt;getLooper()), mReceiverWeakGlobal(env-&gt;NewGlobalRef(receiverWeak)), mMessageQueue(messageQueue), mWaitingForVsync(false) &#123; ALOGV(&quot;receiver %p ~ Initializing display event receiver.&quot;, this);&#125; 通过下面代码知道NativeDisplayEventReceiver是继承自DisplayEventDispatcher的，而NativeDisplayEventReceiver中没有initialize()，于是我们知道status_t status = receiver-&gt;initialize();调用的是NativeDisplayEventReceiver的initialize()： 12345678910111213141516//frameworks\\base\\libs\\androidfw\\DisplayEventDispatcher.cppstatus_t DisplayEventDispatcher::initialize() &#123; status_t result = mReceiver.initCheck(); if (result) &#123; ALOGW(&quot;Failed to initialize display event receiver, status=%d&quot;, result); return result; &#125; int rc = mLooper-&gt;addFd(mReceiver.getFd(), 0, Looper::EVENT_INPUT, this, NULL); if (rc &lt; 0) &#123; return UNKNOWN_ERROR; &#125; return OK;&#125; DisplayEventDispatcher是继承自LooperCallback 的，在DisplayEventDispatcher::initialize()中调用了 12int rc = mLooper-&gt;addFd(mReceiver.getFd(), 0, Looper::EVENT_INPUT, this, NULL); 这句话的意思是监听mReceiver,一旦有数据到来则回调this(此处DisplayEventDispatcher)中所复写LooperCallback对象的 handleEvent。 12345678910111213141516171819//frameworks/base/libs/androidfw/DisplayEventDispatcher.cppint DisplayEventDispatcher::handleEvent(int, int events, ... ... // Drain all pending events, keep the last vsync. nsecs_t vsyncTimestamp; int32_t vsyncDisplayId; uint32_t vsyncCount; //清除所有的pending事件，只保留最后一次vsync if (processPendingEvents(&amp;vsyncTimestamp, &amp;vsyncDisplayId, &amp;vsyncCount)) &#123; ALOGV(&quot;dispatcher %p ~ Vsync pulse: timestamp=%&quot; PRId64 &quot;, id=%d, count=%d&quot;, this, ns2ms(vsyncTimestamp), vsyncDisplayId, vsyncCount); mWaitingForVsync = false; //分发Vsync dispatchVsync(vsyncTimestamp, vsyncDisplayId, vsyncCount); &#125; return 1; // keep the callback&#125; handleEvent()倒数第5行会调用到NativeDisplayEventReceiver的复写的dispatchVsync()： 12345678910111213141516frameworks/base/core/jni/android_view_DisplayEventReceiver.cppvoid NativeDisplayEventReceiver::dispatchVsync(nsecs_t timestamp, int32_t id, uint32_t count) &#123; JNIEnv* env = AndroidRuntime::getJNIEnv(); ScopedLocalRef&lt;jobject&gt; receiverObj(env, jniGetReferent(env, mReceiverWeakGlobal)); if (receiverObj.get()) &#123; ALOGV(&quot;receiver %p ~ Invoking vsync handler.&quot;, this); //此处调用到Java层的DisplayEventReceiver对象的dispatchVsync()方法 env-&gt;CallVoidMethod(receiverObj.get(), gDisplayEventReceiverClassInfo.dispatchVsync, timestamp, id, count); ALOGV(&quot;receiver %p ~ Returned from vsync handler.&quot;, this); &#125; mMessageQueue-&gt;raiseAndClearException(env, &quot;dispatchVsync&quot;);&#125; 调用4个回调链表确定帧信息在NativeDisplayEventReceiver::dispatchVsync通过如下代码调用java层DisplayEventReceiver的dispatchVsync(). 12env-&gt;CallVoidMethod(receiverObj.get(), gDisplayEventReceiverClassInfo.dispatchVsync, timestamp, id, count); 我们回到NativeDisplayEventReceiver.dispatchVsync(): 1234567//android.view.DisplayEventReceiver// Called from native code. @SuppressWarnings(&quot;unused&quot;) private void dispatchVsync(long timestampNanos, int builtInDisplayId, int frame) &#123; onVsync(timestampNanos, builtInDisplayId, frame); &#125; Choreographer对象实例化的过程，创建的对象是DisplayEventReceiver子类 FrameDisplayEventReceiver对象，我们进入FrameDisplayEventReceiver复写的onVsync方法： 123456789101112131415161718192021222324252627282930private final class FrameDisplayEventReceiver extends DisplayEventReceiver implements Runnable &#123; private boolean mHavePendingVsync; private long mTimestampNanos; private int mFrame; @Override public void onVsync(long timestampNanos, int builtInDisplayId, int frame) &#123; //忽略来自第二显示屏的Vsync if (builtInDisplayId != SurfaceControl.BUILT_IN_DISPLAY_ID_MAIN) &#123; scheduleVsync(); return; &#125; ... mTimestampNanos = timestampNanos; mFrame = frame; //该消息的callback为当前对象FrameDisplayEventReceiver Message msg = Message.obtain(mHandler, this); msg.setAsynchronous(true); //此处mHandler为FrameHandler mHandler.sendMessageAtTime(msg, timestampNanos / TimeUtils.NANOS_PER_MS); &#125; @Override public void run() &#123; mHavePendingVsync = false; doFrame(mTimestampNanos, mFrame); //【见小节2.8】 &#125;&#125; 可见onVsync()中是通过FrameHandler向主线程Looper发送了一个自带callback的消息， callback为FrameDisplayEventReceiver。 当主线程Looper执行到该消息时，则调用FrameDisplayEventReceiver.run()，紧接着便是调用doFrame() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475//android.view.Choreographervoid doFrame(long frameTimeNanos, int frame) &#123; final long startNanos; synchronized (mLock) &#123; if (!mFrameScheduled) &#123; return; // no work to do &#125; if (DEBUG_JANK &amp;&amp; mDebugPrintNextFrameTimeDelta) &#123; mDebugPrintNextFrameTimeDelta = false; Log.d(TAG, &quot;Frame time delta: &quot; + ((frameTimeNanos - mLastFrameTimeNanos) * 0.000001f) + &quot; ms&quot;); &#125; long intendedFrameTimeNanos = frameTimeNanos; startNanos = System.nanoTime(); final long jitterNanos = startNanos - frameTimeNanos; if (jitterNanos &gt;= mFrameIntervalNanos) &#123; final long skippedFrames = jitterNanos / mFrameIntervalNanos; if (skippedFrames &gt;= SKIPPED_FRAME_WARNING_LIMIT) &#123; Log.i(TAG, &quot;Skipped &quot; + skippedFrames + &quot; frames! &quot; + &quot;The application may be doing too much work on its main thread.&quot;); &#125; final long lastFrameOffset = jitterNanos % mFrameIntervalNanos; if (DEBUG_JANK) &#123; Log.d(TAG, &quot;Missed vsync by &quot; + (jitterNanos * 0.000001f) + &quot; ms &quot; + &quot;which is more than the frame interval of &quot; + (mFrameIntervalNanos * 0.000001f) + &quot; ms! &quot; + &quot;Skipping &quot; + skippedFrames + &quot; frames and setting frame &quot; + &quot;time to &quot; + (lastFrameOffset * 0.000001f) + &quot; ms in the past.&quot;); &#125; frameTimeNanos = startNanos - lastFrameOffset; &#125; if (frameTimeNanos &lt; mLastFrameTimeNanos) &#123; if (DEBUG_JANK) &#123; Log.d(TAG, &quot;Frame time appears to be going backwards. May be due to a &quot; + &quot;previously skipped frame. Waiting for next vsync.&quot;); &#125; scheduleVsyncLocked(); return; &#125; mFrameInfo.setVsync(intendedFrameTimeNanos, frameTimeNanos); mFrameScheduled = false; mLastFrameTimeNanos = frameTimeNanos; &#125; try &#123; Trace.traceBegin(Trace.TRACE_TAG_VIEW, &quot;Choreographer#doFrame&quot;); AnimationUtils.lockAnimationClock(frameTimeNanos / TimeUtils.NANOS_PER_MS); mFrameInfo.markInputHandlingStart(); doCallbacks(Choreographer.CALLBACK_INPUT, frameTimeNanos); mFrameInfo.markAnimationsStart(); doCallbacks(Choreographer.CALLBACK_ANIMATION, frameTimeNanos); mFrameInfo.markPerformTraversalsStart(); doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos); doCallbacks(Choreographer.CALLBACK_COMMIT, frameTimeNanos); &#125; finally &#123; AnimationUtils.unlockAnimationClock(); Trace.traceEnd(Trace.TRACE_TAG_VIEW); &#125; if (DEBUG_FRAMES) &#123; final long endNanos = System.nanoTime(); Log.d(TAG, &quot;Frame &quot; + frame + &quot;: Finished, took &quot; + (endNanos - startNanos) * 0.000001f + &quot; ms, latency &quot; + (startNanos - frameTimeNanos) * 0.000001f + &quot; ms.&quot;); &#125; &#125; 每调用一次scheduleFrameLocked()，则mFrameScheduled为true，能执行一次 doFrame()操作。doframe的大致流程如下： 总结起来其实主要是三个操作： 1.设置当前frame的启动时间。判断是否跳帧，若跳帧修正当前frame的启动时间到最近的VSync信号时间。如果没跳帧，当前frame启动时间直接设置为当前VSync信号时间。修正完时间后，无论当前frame是否跳帧，使得当前frame的启动时间与VSync信号还是在一个节奏上的，可能可能延后了一到几个周期，但是节奏点还是吻合的。如下图所示是时间修正的一个例子，由于第二个frame执行超时，第三个frame实际启动时间比第三个VSync信号到来时间要晚，因为这时候延时比较小，没有超过一个时钟周期，系统还是将frameTimeNanos3传给回调，回调拿到的时间和VSync信号同步。再来看看下图：由于第二个frame执行时间超过2个时钟周期，导致第三个frame延后执行时间大于一个时钟周期，系统认为这时候影响较大，判定为跳帧了，将第三个frame的时间修正为frameTimeNanos4,比VSync真正到来的时间晚了一个时钟周期。时间修正，既保证了doFrame操作和VSync保持同步节奏，又保证实际启动时间与记录的时间点相差不会太大，便于同步及分析。2.判断是否事件回溯在doframe中 如下代码判断是否时间回溯： 123456789101112if (frameTimeNanos &lt; mLastFrameTimeNanos) &#123; if (DEBUG_JANK) &#123; Log.d(TAG, &quot;Frame time appears to be going backwards. May be due to a &quot; + &quot;previously skipped frame. Waiting for next vsync.&quot;); &#125; scheduleVsyncLocked(); return; &#125; mFrameInfo.setVsync(intendedFrameTimeNanos, frameTimeNanos); mFrameScheduled = false; mLastFrameTimeNanos = frameTimeNanos; 我们在看下FrameDisplayEventReceiver ： 12345678910111213141516171819private final class FrameDisplayEventReceiver extends DisplayEventReceiver implements Runnable &#123; ···· ··· @Override public void onVsync(long timestampNanos, int builtInDisplayId, int frame) &#123; ··· ··· mTimestampNanos = timestampNanos; mFrame = frame; Message msg = Message.obtain(mHandler, this); msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, timestampNanos / TimeUtils.NANOS_PER_MS); &#125; @Override public void run() &#123; mHavePendingVsync = false; doFrame(mTimestampNanos, mFrame); &#125; &#125; 可知是通过handler发送message, 然后走run方法执行doFrame的。同样看下图 由于第二个frame执行时间超过3个时钟周期，导致第三个frame延后执行时间大于两个个时钟周期，系统认为这时候影响较大，判定为跳帧了，将第三个frame的时间修正为frameTimeNanos5,比VSync真正到来的时间晚了一个时钟周期。当图中第5个vsync到来时，消息队列中还有3个任务（取出frameTimeNanos1和frameTimeNanos2所对应的任务，还剩frameTimeNanos3和frameTimeNanos4和frameTimeNanos5），当执行frameTimeNanos4所对应的任务时，此时通过frameTimeNanos为frameTimeNanos4 ,mLastFrameTimeNanos 为frameTimeNanos5的值,此时frameTimeNanos&lt;mLastFrameTimeNanos ，即时间回溯。3.顺序执行callBack队列里面的callback. 然后接下来看看doCallbacks的执行过程: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//android.view.Choreographervoid doCallbacks(int callbackType, long frameTimeNanos) &#123; CallbackRecord callbacks; synchronized (mLock) &#123; // We use &quot;now&quot; to determine when callbacks become due because it&apos;s possible // for earlier processing phases in a frame to post callbacks that should run // in a following phase, such as an input event that causes an animation to start. final long now = System.nanoTime(); callbacks = mCallbackQueues[callbackType].extractDueCallbacksLocked( now / TimeUtils.NANOS_PER_MS); if (callbacks == null) &#123; return; &#125; mCallbacksRunning = true; // Update the frame time if necessary when committing the frame. // We only update the frame time if we are more than 2 frames late reaching // the commit phase. This ensures that the frame time which is observed by the // callbacks will always increase from one frame to the next and never repeat. // We never want the next frame&apos;s starting frame time to end up being less than // or equal to the previous frame&apos;s commit frame time. Keep in mind that the // next frame has most likely already been scheduled by now so we play it // safe by ensuring the commit time is always at least one frame behind. if (callbackType == Choreographer.CALLBACK_COMMIT) &#123; final long jitterNanos = now - frameTimeNanos; Trace.traceCounter(Trace.TRACE_TAG_VIEW, &quot;jitterNanos&quot;, (int) jitterNanos); if (jitterNanos &gt;= 2 * mFrameIntervalNanos) &#123; final long lastFrameOffset = jitterNanos % mFrameIntervalNanos + mFrameIntervalNanos; if (DEBUG_JANK) &#123; Log.d(TAG, &quot;Commit callback delayed by &quot; + (jitterNanos * 0.000001f) + &quot; ms which is more than twice the frame interval of &quot; + (mFrameIntervalNanos * 0.000001f) + &quot; ms! &quot; + &quot;Setting frame time to &quot; + (lastFrameOffset * 0.000001f) + &quot; ms in the past.&quot;); mDebugPrintNextFrameTimeDelta = true; &#125; frameTimeNanos = now - lastFrameOffset; mLastFrameTimeNanos = frameTimeNanos; &#125; &#125; &#125; try &#123; Trace.traceBegin(Trace.TRACE_TAG_VIEW, CALLBACK_TRACE_TITLES[callbackType]); for (CallbackRecord c = callbacks; c != null; c = c.next) &#123; if (DEBUG_FRAMES) &#123; Log.d(TAG, &quot;RunCallback: type=&quot; + callbackType + &quot;, action=&quot; + c.action + &quot;, token=&quot; + c.token + &quot;, latencyMillis=&quot; + (SystemClock.uptimeMillis() - c.dueTime)); &#125; c.run(frameTimeNanos); &#125; &#125; finally &#123; synchronized (mLock) &#123; mCallbacksRunning = false; do &#123; final CallbackRecord next = callbacks.next; recycleCallbackLocked(callbacks); callbacks = next; &#125; while (callbacks != null); &#125; Trace.traceEnd(Trace.TRACE_TAG_VIEW); &#125; &#125; callback的类型有以下4种，除了文章一开始提到的3中外，还有一个CALLBACK_COMMIT。 CALLBACK_INPUT：输入CALLBACK_ANIMATION:动画CALLBACK_TRAVERSAL:遍历，执行measure、layout、drawCALLBACK_COMMIT：遍历完成的提交操作，用来修正动画启动时间 然后看上面的源码，分析一下每个callback的执行过程： 1.callbacks = mCallbackQueues[callbackType].extractDueCallbacksLocked( now / TimeUtils.NANOS_PER_MS);得到执行时间在当前时间之前的所有CallBack，保存在单链表中。每种类型的callback按执行时间先后顺序排序分别存在一个单链表里面。为了保证当前callback执行时新post进来的callback在下一个frame时才被执行，这个地方extractDueCallbacksLocked会将需要执行的callback和以后执行的callback断开变成两个链表，新post进来的callback会被放到后面一个链表中。当前frame只会执行前一个链表中的callback，保证了在执行callback时，如果callback中Post相同类型的callback，这些新加的callback将在下一个frame启动后才会被执行。 2.接下来，看一大段注释，如果类型是CALLBACK_COMMIT，并且当前frame渲染时间超过了两个时钟周期，则将当前提交时间修正为上一个垂直同步信号时间。为了保证下一个frame的提交时间和当前frame时间相差为一且不重复。这个地方注释挺难看懂，实际上这个地方CALLBACK_COMMIT是为了解决ValueAnimator的一个问题而引入的，主要是解决因为遍历时间过长导致动画时间启动过长，时间缩短，导致跳帧，这里修正动画第一个frame开始时间延后来改善，这时候才表示动画真正启动。为什么不直接设置当前时间而是回溯一个时钟周期之前的时间呢？看注释，这里如果设置为当前frame时间，因为动画的第一个frame其实已经绘制完成，第二个frame这时候已经开始了，设置为当前时间会导致这两个frame时间一样，导致冲突。详细情况请看官方针对这个问题的修改。Fix animation start jank due to expensive layout operations. 如下图所示： 3.接下来就是调用c.run(frameTimeNanos);执行回调。例如，你可以写一个自定义的FPSFrameCallback继承自Choreographer.FrameCallback，实现里面的doFrame方法。 123456public class FPSFrameCallback implements Choreographer.FrameCallback&#123;@Override public void doFrame(long frameTimeNanos)&#123; //do something &#125;&#125; 通过Choreographer.getInstance().postFrameCallback(new FPSFrameCallback());把你的回调添加到Choreographer之中，那么在下一个frame被渲染的时候就会回调你的callback,执行你定义的doFrame操作，这时候你就可以获取到这一帧的开始渲染时间并做一些自己想做的事情了。 自此FrameDisplayEventReceiver注册及其回调完成 接受并保存控制帧的信息的任务Choreographer维护了一个队列数组，这个数组有4个元素分别对应于 INPUT：输入事件 ANIMATION：动画 TRAVERSAL：窗口刷新 COMMIT：主要是为了处理动画的bug这四个添加的流程大致上是一致的，我们以TRAVERSAL进行说明,从ViewRootImp的scheduleTraversals()方法说起：123456789101112131415//android.view.ViewRootImplvoid scheduleTraversals() &#123; if (!mTraversalScheduled) &#123; mTraversalScheduled = true; mTraversalBarrier = mHandler.getLooper().getQueue().postSyncBarrier(); mChoreographer.postCallback( Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, null); if (!mUnbufferedInputDispatch) &#123; scheduleConsumeBatchedInput(); &#125; notifyRendererOfFramePending(); pokeDrawLockIfNeeded(); &#125; &#125; 会发现调用了mChoreographer.postCallback(): 12345//android.view.Choreographer public void postCallback(int callbackType, Runnable action, Object token) &#123; postCallbackDelayed(callbackType, action, token, 0); &#125; 继续看postCallbackDelayed() 123456789101112//android.view.Choreographer public void postCallbackDelayed(int callbackType, Runnable action, Object token, long delayMillis) &#123; if (action == null) &#123; throw new IllegalArgumentException(&quot;action must not be null&quot;); &#125; if (callbackType &lt; 0 || callbackType &gt; CALLBACK_LAST) &#123; throw new IllegalArgumentException(&quot;callbackType is invalid&quot;); &#125; postCallbackDelayedInternal(callbackType, action, token, delayMillis); &#125; 继续看postCallbackDelayedInternal() 1234567891011121314151617181920212223242526//android.view.Choreographerprivate void postCallbackDelayedInternal(int callbackType, Object action, Object token, long delayMillis) &#123; if (DEBUG_FRAMES) &#123; Log.d(TAG, &quot;PostCallback: type=&quot; + callbackType + &quot;, action=&quot; + action + &quot;, token=&quot; + token + &quot;, delayMillis=&quot; + delayMillis); &#125; synchronized (mLock) &#123; final long now = SystemClock.uptimeMillis(); final long dueTime = now + delayMillis; //添加到mCallbackQueues队列 mCallbackQueues[callbackType].addCallbackLocked(dueTime, action, token); if (dueTime &lt;= now) &#123; scheduleFrameLocked(now); &#125; else &#123; Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_CALLBACK, action); msg.arg1 = callbackType; msg.setAsynchronous(true); //发送消息MSG_DO_SCHEDULE_CALLBACK mHandler.sendMessageAtTime(msg, dueTime); &#125; &#125; &#125; 在这里将callback添加到队列，如果 不是延时直接调用cheduleFrameLocked()方法,如果是则通过handler调用，FrameHandler 代码如下： 12345678910111213141516private final class FrameHandler extends Handler &#123; public void handleMessage(Message msg) &#123; switch (msg.what) &#123; case MSG_DO_FRAME: doFrame(System.nanoTime(), 0); break; case MSG_DO_SCHEDULE_VSYNC: doScheduleVsync(); break; case MSG_DO_SCHEDULE_CALLBACK: doScheduleCallback(msg.arg1); //【见小节3.5】 break; &#125; &#125;&#125; doScheduleCallback(): 12345678910void doScheduleCallback(int callbackType) &#123; synchronized (mLock) &#123; if (!mFrameScheduled) &#123; final long now = SystemClock.uptimeMillis(); if (mCallbackQueues[callbackType].hasDueCallbacksLocked(now)) &#123; scheduleFrameLocked(now); //【见小节3.6】 &#125; &#125; &#125;&#125; 发现调用的是scheduleFrameLocked()： 123456789101112131415161718192021222324252627282930private void scheduleFrameLocked(long now) &#123; if (!mFrameScheduled) &#123; mFrameScheduled = true; if (USE_VSYNC) &#123; if (DEBUG_FRAMES) &#123; Log.d(TAG, &quot;Scheduling next frame on vsync.&quot;); &#125; // If running on the Looper thread, then schedule the vsync immediately, // otherwise post a message to schedule the vsync from the UI thread // as soon as possible. if (isRunningOnLooperThreadLocked()) &#123; scheduleVsyncLocked(); &#125; else &#123; Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_VSYNC); msg.setAsynchronous(true); mHandler.sendMessageAtFrontOfQueue(msg); &#125; &#125; else &#123; final long nextFrameTime = Math.max( mLastFrameTimeNanos / TimeUtils.NANOS_PER_MS + sFrameDelay, now); if (DEBUG_FRAMES) &#123; Log.d(TAG, &quot;Scheduling next frame in &quot; + (nextFrameTime - now) + &quot; ms.&quot;); &#125; Message msg = mHandler.obtainMessage(MSG_DO_FRAME); msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, nextFrameTime); &#125; &#125; &#125; 该方法的功能： 当运行在Looper线程，则立刻调度scheduleVsyncLocked(); 当运行在其他线程，则通过发送一个消息到Looper线程，然后再执行scheduleVsyncLocked();123private void scheduleVsyncLocked() &#123; mDisplayEventReceiver.scheduleVsync(); //【见小节3.8】&#125; mDisplayEventReceiver对象是在Choreographer的实例化过程所创建的。 1234567public void scheduleVsync() &#123; if (mReceiverPtr == 0) &#123; ... &#125; else &#123; nativeScheduleVsync(mReceiverPtr); &#125;&#125; 至此分析大致流程是 找到nativeScheduleVsync所对应的c++文件 123456789//frameworks/base/core/jni/android_view_DisplayEventReceiver.cppstatic void nativeScheduleVsync(JNIEnv* env, jclass clazz, jlong receiverPtr) &#123; sp&lt;NativeDisplayEventReceiver&gt; receiver = reinterpret_cast&lt;NativeDisplayEventReceiver*&gt;(receiverPtr); status_t status = receiver-&gt;scheduleVsync(); ··· ··· &#125;&#125; 因为NativeDisplayEventReceiver 继承DisplayEventReceiver，找到DisplayEventReceiver中scheduleVsync(): 1234567//android.view.DisplayEventReceiverstatus_t DisplayEventDispatcher::scheduleVsync() &#123; ··· ···· status_t status = mReceiver.requestNextVsync(); ··· ···&#125; 该方法的作用请求下一次Vsync信息处理。 当Vsync信号到来，由于mFrameScheduled=true,则继续CallbackRecord.run()方法。 参考：Android的16ms和垂直同步以及三重缓存Choreographer原理Android Choreographer 源码分析","categories":[],"tags":[{"name":"android源码 绘制原理 vysn","slug":"android源码-绘制原理-vysn","permalink":"https://hesitationpencil.github.io/tags/android源码-绘制原理-vysn/"}]},{"title":"android绘制原理","slug":"android绘制原理","date":"2019-06-19T07:19:14.000Z","updated":"2019-06-20T08:20:52.239Z","comments":true,"path":"2019/06/19/android绘制原理/","link":"","permalink":"https://hesitationpencil.github.io/2019/06/19/android绘制原理/","excerpt":"","text":"硬件分工在计算机硬件中, 通常 CPU 用来处理数据, GPU 用来渲染数据. Android 系统也不例外, 绘制过程首先是 CPU 准备数据, 通过 Driver 层把数据交给 GPU 渲染. 其中 CPU 主要负责 Measure 、Layout 、Record 、Execute 的数据计算工作, GPU 负责 Rasterization（栅格化）、渲染. 由于图形 API 不允许 CPU 直接与 GPU 通信, 而是通过中间的一个图形驱动层（Graphics Driver）来连接这两部分. 图形驱动维护了一个队列, CPU 把 display list 添加到队列中, GPU 从这个队列取出数据进行绘制, 最终才在显示屏上显示出来. 那么无论是 CPU 准备的数据, 还是 GPU 渲染的数据, 都是以一帧一帧的形式来的. 我们所看到的界面也是有一帧一帧的图像连续显示而来. 对于人眼来说, 每秒钟看到60帧则比较流畅了, 即 FPS(Frame Per second) 为60, 1/60 = 0.01666667, 即每 16ms 进行一次准备-渲染操作. 系统变更历史在 Android 4.1 以前, 每一次渲染的流程可以用下图表示:横轴表示时间, 每条 VSync 线表示 16ms: 1.时间从0开始，进入第一个16ms：Display显示第0帧，CPU处理完第一帧后，GPU紧接其后处理继续第一帧。三者互不干扰，一切正常。 2.时间进入第二个16ms：因为早在上一个16ms时间内，第1帧已经由CPU，GPU处理完毕。故Display可以直接显示第1帧。显示没有问题。但在本16ms期间，CPU和GPU 却并未及时去绘制第2帧数据（注意前面的空白区），而是在本周期快结束时，CPU/GPU才去处理第2帧数据。 3.时间进入第3个16ms，此时Display应该显示第2帧数据，但由于CPU和GPU还没有处理完第2帧数据，故Display只能继续显示第一帧的数据，结果使得第1 帧多画了一次（对应时间段上标注了一个Jank）。 4.通过上述分析可知，此处发生Jank的关键问题在于，为何第1个16ms段内，CPU/GPU没有及时处理第2帧数据？原因很简单，CPU可能是在忙别的事情（比如某个应用通过sleep 固定时间来实现动画的逐帧显示），不知道该到处理UI绘制的时间了。可CPU一旦想起来要去处理第2帧数据，时间又错过了！ 在 Android 4.1 版本中, 为了解决这些问题推出了 Project Butter, 主要引入 VSync, Triple Buffer和Choreographer. VSync : Vertical Synchronization, 即垂直同步, 可以理解为一种定时中断, GPU 和 CPU 在收到 VSync 信号时开始准备数据.引入 VSync 后的渲染流程如下: 这样每次收到 VSync 中断时, CPU 和 GPU 开始工作. 只要 CPU 和 GPU 的 FPS 略高于 Display 的 FPS, 则每次都能在 16ms 之内准备好下一帧, 能够顺利显示. 如果 CPU 和 GPU 已经准备完毕, 只要没有收到 VSync 信号, 都不会进行渲染工作. Triple Buffer: 即3个缓存块. 在 Android 4.1 以前, 只有2个缓存块用于准备数据, 两个缓存块交替使用. 在引入 VSync 后, 如果 CPU 和 GPU 的 FPS 比 Display 的 FPS 低, 即不能在 16ms 内准备好数据, 会导致很严重的掉帧效果. 在第一个16ms中, 系统显示缓存块A, CPU 和 GPU 在缓存块 B 中准备第1帧. 在第二个16ms中, 由于 GPU 还没有准备好, 所以只能继续显示缓存块 A 的内容, 用户感知到卡顿.为了解决这个问题, Android 4.1 引入第三个缓存块: 在第一个16ms中, 系统显示缓存块A, CPU 和 GPU 在缓存块 B 中准备第1帧. 在第二个16ms中, 由于 GPU 还没有准备好, 所以只能继续显示缓存块 A 的内容, 用户感知到卡顿. 但此时 CPU 可以在缓存块 C 中准备数据. 正常显示不会再丢帧. 但是缓存块并不是越多越好, CPU 和 GPU 准备的数据最好在下一个 16ms 显示, 但是 Triple Buffer 中 CPU 准备的缓存块C, 在第四个 16ms 中才显示, 滞后了 16ms. 所以第三个缓存块主要是备用, 一般来说两个缓存块就够了. Choreographer: 译为舞蹈编排, 起到调度作用, 收到 VSync 信号时调用用户设置的回调函数, 回调类型有三种: CALLBACK_INPUT：优先级最高，和输入事件处理有关。 CALLBACK_ANIMATION：优先级其次，和Animation的处理有关。 CALLBACK_TRAVERSAL：优先级最低，和UI等控件绘制有关。 本文摘自：&emsp;Android 绘制原理&emsp;Android的16ms和垂直同步以及三重缓存","categories":[],"tags":[{"name":"android绘制","slug":"android绘制","permalink":"https://hesitationpencil.github.io/tags/android绘制/"}]}]}